{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   生成输入数据集 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from property_generator import*\n",
    "\n",
    "N_SAMPLE= 16\n",
    "N_WELL=1\n",
    "N_TASKS = 32\n",
    "NUM_CONTRAL_POINT=10\n",
    "PORO_VAR=0.004\n",
    "PERM_VAR=8100\n",
    "LEN_SCALE=[3200, 3200, 80]\n",
    "x = np.arange(1900, 8200, 200)#32 6400\n",
    "y = np.arange(1100, 7400, 200)#32 6400\n",
    "z = np.arange(-2975, -2820, 10)#16 160\n",
    "\n",
    "\n",
    "STEPS=[0,1,3,9,16,22,28,34,40,50]\n",
    "T_STOP=28\n",
    "INJ_RATE=15\n",
    "\n",
    "GetAllTask(x,y,z,N_TASKS, N_SAMPLE,STEPS,T_STOP, INJ_RATE,PORO_VAR, PERM_VAR, LEN_SCALE, NUM_CONTRAL_POINT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "path_comsol_server=\"D:\\comsol\\COMSOL62\\Multiphysics\\bin\\win64\\comsolmphserver.exe\"####检查修改COMSOL的路径设置，符合你自己的PC设置\n",
    "comsol_server_process = subprocess.Popen(path_comsol_server)\n",
    "cmd_matlb_script=\"matlab -nosplash -nodesktop -r StarCOMSOL\" ####检查修改StarCOMSOL中的路径设置，符合你自己的PC设置\n",
    "os.system(cmd_matlb_script)\n",
    "comsol_server_process.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cat_label import CatLabels\n",
    "cols=np.linspace(3, 21, 10, dtype=np.int16)\n",
    "catlabels = CatLabels(\"./\", \"new312\",\"./dataSet\",x,y,z,cols)\n",
    "catlabels.DealAllTask()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from normal_train import*\n",
    "from para import*\n",
    "\n",
    "def plot(log, selected_epoch, name='log'):\n",
    "    fig,ax = plt.subplots(figsize=(6, 4))\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    if len(np.shape(log))==1:\n",
    "        x=np.arange(1,len(log)+1)\n",
    "        y=log\n",
    "        ax.plot(x, y)\n",
    "    else:\n",
    "        x=np.arange(1,len(log[0])+1)\n",
    "        for row in selected_epoch:\n",
    "            y=log[row]\n",
    "            ax.plot(x, y, label=f'epoch{row}')\n",
    "    fig.legend()\n",
    "    fig.savefig(f'{name}.png',dpi=500)\n",
    "    fig.show()\n",
    "\n",
    "def plot_compare(log1, log2, name='log'):\n",
    "    fig,ax = plt.subplots(figsize=(6, 4))\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel(f'{name}') \n",
    "    x=np.arange(1,len(log1)+1)\n",
    "    y=log1\n",
    "    ax.plot(x, y, label=f'reptile')\n",
    "    y=log2\n",
    "    ax.plot(x, y, label=f'reptile')\n",
    "    fig.savefig(f'{name}.png',dpi=500)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Avaliable samples: 63\n",
      "-----------------------------------------normalloss_mse_lr0.001_ns16---------------------------------------------\n",
      "epoch0  eval loss:0.005092544015496969 r2:-2.411942720413208\n",
      "epoch1  eval loss:0.012686465866863728 r2:-7.499778747558594\n",
      "epoch2  eval loss:0.012549427337944508 r2:-7.407964706420898\n",
      "epoch3  eval loss:0.008149559609591961 r2:-4.460106372833252\n",
      "epoch4  eval loss:0.0033270777203142643 r2:-1.2291016578674316\n",
      "epoch5  eval loss:0.0026831079740077257 r2:-0.7976498603820801\n",
      "epoch6  eval loss:0.002145608654245734 r2:-0.43753182888031006\n",
      "epoch7  eval loss:0.0023064687848091125 r2:-0.5453062057495117\n",
      "epoch8  eval loss:0.0018715382320806384 r2:-0.2539079189300537\n",
      "epoch9  eval loss:0.0016514426097273827 r2:-0.10644650459289551\n",
      "epoch10  eval loss:0.0018856695387512445 r2:-0.26337575912475586\n",
      "epoch11  eval loss:0.0018744695698842406 r2:-0.25587189197540283\n",
      "epoch12  eval loss:0.001598075614310801 r2:-0.07069134712219238\n",
      "epoch13  eval loss:0.001505133113823831 r2:-0.008420944213867188\n",
      "epoch14  eval loss:0.001547594671137631 r2:-0.03686964511871338\n",
      "epoch15  eval loss:0.0015261612134054303 r2:-0.02250957489013672\n",
      "epoch16  eval loss:0.001501687802374363 r2:-0.00611269474029541\n",
      "epoch17  eval loss:0.0015417777467519045 r2:-0.03297233581542969\n",
      "epoch18  eval loss:0.0015707260463386774 r2:-0.052367448806762695\n",
      "epoch19  eval loss:0.0015356378862634301 r2:-0.02885878086090088\n",
      "epoch20  eval loss:0.0015028337948024273 r2:-0.006880402565002441\n",
      "epoch21  eval loss:0.0015106674982234836 r2:-0.012128949165344238\n",
      "epoch22  eval loss:0.0015160542679950595 r2:-0.01573801040649414\n",
      "epoch23  eval loss:0.0014975146623328328 r2:-0.003316640853881836\n",
      "epoch24  eval loss:0.0014876964269205928 r2:0.0032614469528198242\n",
      "epoch25  eval loss:0.0014924213755875826 r2:9.578466415405273e-05\n",
      "epoch26  eval loss:0.0014889405574649572 r2:0.0024278759956359863\n",
      "epoch27  eval loss:0.0014689469244331121 r2:0.0158233642578125\n",
      "epoch28  eval loss:0.001460902625694871 r2:0.02121293544769287\n",
      "epoch29  eval loss:0.001462549902498722 r2:0.02010929584503174\n",
      "epoch30  eval loss:0.0014591540675610304 r2:0.022384464740753174\n",
      "epoch31  eval loss:0.0014644373441115022 r2:0.01884472370147705\n",
      "epoch32  eval loss:0.001466197776608169 r2:0.01766526699066162\n",
      "epoch33  eval loss:0.001484279753640294 r2:0.005550563335418701\n",
      "epoch34  eval loss:0.0015223323134705424 r2:-0.019944190979003906\n",
      "epoch35  eval loss:0.0014928648015484214 r2:-0.00020134449005126953\n",
      "epoch36  eval loss:0.0014950259355828166 r2:-0.0016492605209350586\n",
      "epoch37  eval loss:0.0015363902784883976 r2:-0.029362916946411133\n",
      "epoch38  eval loss:0.0015368370804935694 r2:-0.029662251472473145\n",
      "epoch39  eval loss:0.002043086104094982 r2:-0.3688429594039917\n",
      "epoch40  eval loss:0.0014699657913297415 r2:0.015140771865844727\n",
      "epoch41  eval loss:0.0015153588028624654 r2:-0.015272021293640137\n",
      "epoch42  eval loss:0.000999525422230363 r2:0.3303300738334656\n",
      "epoch43  eval loss:0.0010091817239299417 r2:0.3238604664802551\n",
      "epoch44  eval loss:0.0009497649152763188 r2:0.3636690378189087\n",
      "epoch45  eval loss:0.0008416668861173093 r2:0.43609338998794556\n",
      "epoch46  eval loss:0.0008262083283625543 r2:0.44645047187805176\n",
      "epoch47  eval loss:0.000829012889880687 r2:0.44457143545150757\n",
      "epoch48  eval loss:0.0009182015783153474 r2:0.38481611013412476\n",
      "epoch49  eval loss:0.000875369762070477 r2:0.4135128855705261\n",
      "epoch50  eval loss:0.0009526775102131069 r2:0.3617175817489624\n",
      "epoch51  eval loss:0.0009221737273037434 r2:0.38215476274490356\n",
      "epoch52  eval loss:0.0010434092255309224 r2:0.3009284734725952\n",
      "epoch53  eval loss:0.0008848017896525562 r2:0.40719348192214966\n",
      "epoch54  eval loss:0.0008173235110007226 r2:0.45240318775177\n",
      "epoch55  eval loss:0.0007745246984995902 r2:0.4810778498649597\n",
      "epoch56  eval loss:0.0007817206787876785 r2:0.4762566089630127\n",
      "epoch57  eval loss:0.0008056273800320923 r2:0.4602394104003906\n",
      "epoch58  eval loss:0.0007960392395034432 r2:0.4666633605957031\n",
      "epoch59  eval loss:0.0007921562646515667 r2:0.4692649245262146\n",
      "epoch60  eval loss:0.0008416459313593805 r2:0.43610745668411255\n",
      "epoch61  eval loss:0.0008957652607932687 r2:0.39984816312789917\n",
      "epoch62  eval loss:0.0008305093506351113 r2:0.4435688257217407\n",
      "epoch63  eval loss:0.0008129837224259973 r2:0.45531076192855835\n",
      "epoch64  eval loss:0.0007548183784820139 r2:0.4942808151245117\n",
      "epoch65  eval loss:0.0007387622608803213 r2:0.5050382614135742\n",
      "epoch66  eval loss:0.0006939830491319299 r2:0.5350397825241089\n",
      "epoch67  eval loss:0.0007648348691873252 r2:0.4875698685646057\n",
      "epoch68  eval loss:0.0007730457582511008 r2:0.4820687174797058\n",
      "epoch69  eval loss:0.0007801064639352262 r2:0.47733813524246216\n",
      "epoch70  eval loss:0.000750634993892163 r2:0.4970836639404297\n",
      "epoch71  eval loss:0.0006927942740730941 r2:0.5358362197875977\n",
      "epoch72  eval loss:0.0006923141190782189 r2:0.5361579656600952\n",
      "epoch73  eval loss:0.0006846775650046766 r2:0.5412743091583252\n",
      "epoch74  eval loss:0.0007066276739351451 r2:0.5265679955482483\n",
      "epoch75  eval loss:0.000707246654201299 r2:0.5261533260345459\n",
      "epoch76  eval loss:0.000722769065760076 r2:0.5157535076141357\n",
      "epoch77  eval loss:0.0007122834795154631 r2:0.5227786898612976\n",
      "epoch78  eval loss:0.0007243357831612229 r2:0.5147038102149963\n",
      "epoch79  eval loss:0.000728009210433811 r2:0.5122426748275757\n",
      "epoch80  eval loss:0.0007188972667790949 r2:0.5183475017547607\n",
      "epoch81  eval loss:0.0007033111178316176 r2:0.5287901163101196\n",
      "epoch82  eval loss:0.000710817810613662 r2:0.5237606763839722\n",
      "epoch83  eval loss:0.0007250154740177095 r2:0.5142484307289124\n",
      "epoch84  eval loss:0.0007234442164190114 r2:0.5153011083602905\n",
      "epoch85  eval loss:0.0007091953884810209 r2:0.524847686290741\n",
      "epoch86  eval loss:0.0007105238037183881 r2:0.5239576697349548\n",
      "epoch87  eval loss:0.00071798509452492 r2:0.5189586877822876\n",
      "epoch88  eval loss:0.0007070085848681629 r2:0.5263128280639648\n",
      "epoch89  eval loss:0.0006756015354767442 r2:0.5473551750183105\n",
      "epoch90  eval loss:0.0007067816331982613 r2:0.5264648199081421\n",
      "epoch91  eval loss:0.0006901446031406522 r2:0.5376114845275879\n",
      "epoch92  eval loss:0.0007109532016329467 r2:0.523669958114624\n",
      "epoch93  eval loss:0.0007267702021636069 r2:0.5130727291107178\n",
      "epoch94  eval loss:0.0006906338385306299 r2:0.537283718585968\n",
      "epoch95  eval loss:0.0006881503504700959 r2:0.538947582244873\n",
      "epoch96  eval loss:0.0006879419088363647 r2:0.5390872955322266\n",
      "epoch97  eval loss:0.0006919529987499118 r2:0.5363998413085938\n",
      "epoch98  eval loss:0.0007856306037865579 r2:0.47363704442977905\n",
      "epoch99  eval loss:0.0007203168934211135 r2:0.5173964500427246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------normalloss_mse_lr0.001_ns32---------------------------------------------\n",
      "epoch0  eval loss:0.030209019780158997 r2:-27.811105728149414\n",
      "epoch1  eval loss:0.01786147430539131 r2:-10.95819091796875\n",
      "epoch2  eval loss:0.004468063358217478 r2:-3.191244602203369\n",
      "epoch3  eval loss:0.0034866956993937492 r2:-2.1236419677734375\n",
      "epoch4  eval loss:0.0014850350562483072 r2:-0.24340999126434326\n",
      "epoch5  eval loss:0.0018217936158180237 r2:-1.5581269264221191\n",
      "epoch6  eval loss:0.0017175044631585479 r2:-0.173805832862854\n",
      "epoch7  eval loss:0.0015665924875065684 r2:-0.25426673889160156\n",
      "epoch8  eval loss:0.0014527362072840333 r2:-0.1719902753829956\n",
      "epoch9  eval loss:0.0016048422548919916 r2:-0.047772884368896484\n",
      "epoch10  eval loss:0.00137109006755054 r2:-0.13215851783752441\n",
      "epoch11  eval loss:0.0011896002106368542 r2:-0.08572936058044434\n",
      "epoch12  eval loss:0.0013361419551074505 r2:-0.07571887969970703\n",
      "epoch13  eval loss:0.0012585707008838654 r2:-0.057744741439819336\n",
      "epoch14  eval loss:0.001250221859663725 r2:-0.0775613784790039\n",
      "epoch15  eval loss:0.0010586758144199848 r2:-0.1780174970626831\n",
      "epoch16  eval loss:0.001250607892870903 r2:-0.08620333671569824\n",
      "epoch17  eval loss:0.001346222939901054 r2:-0.0163804292678833\n",
      "epoch18  eval loss:0.001352130901068449 r2:-0.018116474151611328\n",
      "epoch19  eval loss:0.001243778970092535 r2:-0.046387672424316406\n",
      "epoch20  eval loss:0.0014768850523978472 r2:-0.015455245971679688\n",
      "epoch21  eval loss:0.0012179056648164988 r2:-0.053177475929260254\n",
      "epoch22  eval loss:0.0015147845260798931 r2:0.01112288236618042\n",
      "epoch23  eval loss:0.001227224012836814 r2:-0.033258795738220215\n",
      "epoch24  eval loss:0.001252083806321025 r2:-0.007608652114868164\n",
      "epoch25  eval loss:0.0013321914011612535 r2:-0.0044879913330078125\n",
      "epoch26  eval loss:0.0012248354032635689 r2:-0.007215261459350586\n",
      "epoch27  eval loss:0.0012647510739043355 r2:0.005894958972930908\n",
      "epoch28  eval loss:0.0012005369644612074 r2:0.007877826690673828\n",
      "epoch29  eval loss:0.0009990106336772442 r2:-0.11978781223297119\n",
      "epoch30  eval loss:0.0011764715891331434 r2:0.08099347352981567\n",
      "epoch31  eval loss:0.000769575301092118 r2:-0.1974334716796875\n",
      "epoch32  eval loss:0.000759274757001549 r2:-0.0007328987121582031\n",
      "epoch33  eval loss:0.000930891721509397 r2:0.42778313159942627\n",
      "epoch34  eval loss:0.0006265657721087337 r2:-0.08134675025939941\n",
      "epoch35  eval loss:0.0006172339199110866 r2:-0.0937119722366333\n",
      "epoch36  eval loss:0.0006291886093094945 r2:0.4596445560455322\n",
      "epoch37  eval loss:0.0006249059224501252 r2:0.5158664584159851\n",
      "epoch38  eval loss:0.0005871026660315692 r2:0.5380398035049438\n",
      "epoch39  eval loss:0.0006457194685935974 r2:0.42994892597198486\n",
      "epoch40  eval loss:0.0006420715944841504 r2:0.6071581840515137\n",
      "epoch41  eval loss:0.0006185492966324091 r2:0.5096248388290405\n",
      "epoch42  eval loss:0.0005304993828758597 r2:0.5857573747634888\n",
      "epoch43  eval loss:0.0006432250374928117 r2:0.5028485059738159\n",
      "epoch44  eval loss:0.0005507246823981404 r2:0.5809224843978882\n",
      "epoch45  eval loss:0.0005672497791238129 r2:0.5044721364974976\n",
      "epoch46  eval loss:0.0005808155983686447 r2:0.5315141677856445\n",
      "epoch47  eval loss:0.00048131789662875235 r2:0.14736205339431763\n",
      "epoch48  eval loss:0.000424765981733799 r2:0.7097613215446472\n",
      "epoch49  eval loss:0.0004827877273783088 r2:0.6282471418380737\n",
      "epoch50  eval loss:0.000539576867595315 r2:0.5206229090690613\n",
      "epoch51  eval loss:0.00041907530976459384 r2:0.6313941478729248\n",
      "epoch52  eval loss:0.00039839698001742363 r2:0.7087087631225586\n",
      "epoch53  eval loss:0.00042064886656589806 r2:0.6844695806503296\n",
      "epoch54  eval loss:0.00039821190875954926 r2:0.8131504058837891\n",
      "epoch55  eval loss:0.00035640207352116704 r2:0.7470141649246216\n",
      "epoch56  eval loss:0.00040892657125368714 r2:0.6428483724594116\n",
      "epoch57  eval loss:0.0004097306518815458 r2:0.7928786277770996\n",
      "epoch58  eval loss:0.0003626593970693648 r2:0.7654324173927307\n",
      "epoch59  eval loss:0.000378252356313169 r2:0.8010293841362\n",
      "epoch60  eval loss:0.0003675779444165528 r2:0.8406161665916443\n",
      "epoch61  eval loss:0.0004492097650654614 r2:0.656766414642334\n",
      "epoch62  eval loss:0.0004099083016626537 r2:0.7620865702629089\n",
      "epoch63  eval loss:0.0004806024953722954 r2:-0.0058133602142333984\n",
      "epoch64  eval loss:0.0003757942467927933 r2:0.37475574016571045\n",
      "epoch65  eval loss:0.0003380890120752156 r2:0.8437845706939697\n",
      "epoch66  eval loss:0.0004019946209155023 r2:0.27840012311935425\n",
      "epoch67  eval loss:0.00037730479380115867 r2:0.17801523208618164\n",
      "epoch68  eval loss:0.0003139976761303842 r2:0.7493968605995178\n",
      "epoch69  eval loss:0.0004412969574332237 r2:0.6063095331192017\n",
      "epoch70  eval loss:0.00030287407571449876 r2:0.7587066888809204\n",
      "epoch71  eval loss:0.000336677476298064 r2:0.7276224493980408\n",
      "epoch72  eval loss:0.00040269637247547507 r2:0.7181761264801025\n",
      "epoch73  eval loss:0.00031937722815200686 r2:0.7235465049743652\n",
      "epoch74  eval loss:0.00029972282936796546 r2:0.7657362222671509\n",
      "epoch75  eval loss:0.0003623860247898847 r2:0.38071972131729126\n",
      "epoch76  eval loss:0.00040378590347245336 r2:0.15430784225463867\n",
      "epoch77  eval loss:0.0003276727511547506 r2:0.7981929779052734\n",
      "epoch78  eval loss:0.0003533309791237116 r2:0.750235915184021\n",
      "epoch79  eval loss:0.00036210118560120463 r2:0.18068230152130127\n",
      "epoch80  eval loss:0.00036569725489243865 r2:0.4687342643737793\n",
      "epoch81  eval loss:0.00033864215947687626 r2:0.7640830278396606\n",
      "epoch82  eval loss:0.00030568052898161113 r2:0.7906416058540344\n",
      "epoch83  eval loss:0.00036451517371460795 r2:0.7336759567260742\n",
      "epoch84  eval loss:0.0003177093749400228 r2:0.7683815360069275\n",
      "epoch85  eval loss:0.00039792119059711695 r2:0.6804332733154297\n",
      "epoch86  eval loss:0.00030644936487078667 r2:0.873620867729187\n",
      "epoch87  eval loss:0.0003259404911659658 r2:0.7032408714294434\n",
      "epoch88  eval loss:0.00026306320796720684 r2:0.5731825828552246\n",
      "epoch89  eval loss:0.00033036922104656696 r2:0.7038209438323975\n",
      "epoch90  eval loss:0.00028586521511897445 r2:0.7509571313858032\n",
      "epoch91  eval loss:0.00030668609542772174 r2:0.736143946647644\n",
      "epoch92  eval loss:0.00030532892560586333 r2:0.7812699675559998\n",
      "epoch93  eval loss:0.0002917993115261197 r2:0.8552501797676086\n",
      "epoch94  eval loss:0.0003163625078741461 r2:0.4996129870414734\n",
      "epoch95  eval loss:0.00030759733635932207 r2:0.4285030961036682\n",
      "epoch96  eval loss:0.0003214280295651406 r2:0.7246263027191162\n",
      "epoch97  eval loss:0.0003522950573824346 r2:0.47400498390197754\n",
      "epoch98  eval loss:0.00033770600566640496 r2:0.7631662487983704\n",
      "epoch99  eval loss:0.00029701468884013593 r2:0.8396108746528625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------normalloss_mse_lr0.001_ns64---------------------------------------------\n",
      "epoch0  eval loss:0.015672652050852776 r2:-12.048540115356445\n",
      "epoch1  eval loss:0.004159256815910339 r2:-1.542574167251587\n",
      "epoch2  eval loss:0.0022625781130045652 r2:-0.37586867809295654\n",
      "epoch3  eval loss:0.0017043785192072392 r2:-0.3733339309692383\n",
      "epoch4  eval loss:0.0017785015515983105 r2:-0.11846065521240234\n",
      "epoch5  eval loss:0.001671105157583952 r2:-0.08650338649749756\n",
      "epoch6  eval loss:0.0017132129287347198 r2:-0.07522034645080566\n",
      "epoch7  eval loss:0.0017064193962141871 r2:-0.03360772132873535\n",
      "epoch8  eval loss:0.0016428617527708411 r2:-0.03759598731994629\n",
      "epoch9  eval loss:0.001510458067059517 r2:-0.04869246482849121\n",
      "epoch10  eval loss:0.001656778622418642 r2:-0.00886523723602295\n",
      "epoch11  eval loss:0.0015773200429975986 r2:-0.02069556713104248\n",
      "epoch12  eval loss:0.0015993925044313073 r2:0.006013035774230957\n",
      "epoch13  eval loss:0.0015395913505926728 r2:0.04476219415664673\n",
      "epoch14  eval loss:0.001260401331819594 r2:0.10282838344573975\n",
      "epoch15  eval loss:0.0010325401090085506 r2:0.22951817512512207\n",
      "epoch16  eval loss:0.0009792445925995708 r2:0.3806617259979248\n",
      "epoch17  eval loss:0.0009291341993957758 r2:0.3232109546661377\n",
      "epoch18  eval loss:0.0008542214636690915 r2:0.2934437394142151\n",
      "epoch19  eval loss:0.0008281042682938278 r2:0.37729746103286743\n",
      "epoch20  eval loss:0.0011115435045212507 r2:-0.17405474185943604\n",
      "epoch21  eval loss:0.000767446996178478 r2:0.3771619200706482\n",
      "epoch22  eval loss:0.0007748114294372499 r2:0.471752405166626\n",
      "epoch23  eval loss:0.0007297701667994261 r2:0.5400891900062561\n",
      "epoch24  eval loss:0.000740323681384325 r2:0.5327779054641724\n",
      "epoch25  eval loss:0.0008409865549765527 r2:0.49338704347610474\n",
      "epoch26  eval loss:0.0008369141141884029 r2:0.33436357975006104\n",
      "epoch27  eval loss:0.0009690127335488796 r2:0.3535827398300171\n",
      "epoch28  eval loss:0.0007354093831963837 r2:0.4964340925216675\n",
      "epoch29  eval loss:0.0008709575049579144 r2:0.5023363828659058\n",
      "epoch30  eval loss:0.00077091931598261 r2:0.4617169499397278\n",
      "epoch31  eval loss:0.0007764192414470017 r2:0.4740617871284485\n",
      "epoch32  eval loss:0.0006803555297665298 r2:0.5619361400604248\n",
      "epoch33  eval loss:0.0007509870920330286 r2:0.5556124448776245\n",
      "epoch34  eval loss:0.0006686947890557349 r2:0.5620790719985962\n",
      "epoch35  eval loss:0.000819335225969553 r2:0.34414273500442505\n",
      "epoch36  eval loss:0.0006626652902923524 r2:0.6061114072799683\n",
      "epoch37  eval loss:0.0006978979799896479 r2:0.49056828022003174\n",
      "epoch38  eval loss:0.0006836771499365568 r2:0.49751102924346924\n",
      "epoch39  eval loss:0.0006771041080355644 r2:0.5550686120986938\n",
      "epoch40  eval loss:0.000666007399559021 r2:0.5834230184555054\n",
      "epoch41  eval loss:0.0006432654336094856 r2:0.6132403612136841\n",
      "epoch42  eval loss:0.000616006029304117 r2:0.6045597791671753\n",
      "epoch43  eval loss:0.0005785253015346825 r2:0.649088978767395\n",
      "epoch44  eval loss:0.0005997863481752574 r2:0.48641788959503174\n",
      "epoch45  eval loss:0.0005557447439059615 r2:0.6806602478027344\n",
      "epoch46  eval loss:0.0005763871595263481 r2:0.6886371374130249\n",
      "epoch47  eval loss:0.000573420780710876 r2:0.6771110892295837\n",
      "epoch48  eval loss:0.0005632953834719956 r2:0.5579016208648682\n",
      "epoch49  eval loss:0.0005981037393212318 r2:0.5338273048400879\n",
      "epoch50  eval loss:0.0006460626027546823 r2:0.5418669581413269\n",
      "epoch51  eval loss:0.000565457041375339 r2:0.7105752825737\n",
      "epoch52  eval loss:0.0006019133725203574 r2:0.6474771499633789\n",
      "epoch53  eval loss:0.0005093232612125576 r2:0.7322095632553101\n",
      "epoch54  eval loss:0.0005084233707748353 r2:0.6004472970962524\n",
      "epoch55  eval loss:0.0005377326160669327 r2:0.6960290670394897\n",
      "epoch56  eval loss:0.0004314816033001989 r2:0.692629337310791\n",
      "epoch57  eval loss:0.00043943538912571967 r2:0.6626137495040894\n",
      "epoch58  eval loss:0.000466787168988958 r2:0.6675559282302856\n",
      "epoch59  eval loss:0.0004557609499897808 r2:0.7242000102996826\n",
      "epoch60  eval loss:0.00045396402128972113 r2:0.7266629934310913\n",
      "epoch61  eval loss:0.0004296761762816459 r2:0.7471103668212891\n",
      "epoch62  eval loss:0.00043283705599606037 r2:0.7158147096633911\n",
      "epoch63  eval loss:0.0004730765940621495 r2:0.7121739387512207\n",
      "epoch64  eval loss:0.00047133254702202976 r2:0.6700630187988281\n",
      "epoch65  eval loss:0.00042919404222629964 r2:0.7110023498535156\n",
      "epoch66  eval loss:0.00048034568317234516 r2:0.7060998678207397\n",
      "epoch67  eval loss:0.00046517184819094837 r2:0.6676258444786072\n",
      "epoch68  eval loss:0.0005363664240576327 r2:0.6709375977516174\n",
      "epoch69  eval loss:0.00046250829473137856 r2:0.6063169240951538\n",
      "epoch70  eval loss:0.00045690545812249184 r2:0.6367602348327637\n",
      "epoch71  eval loss:0.0004763615725096315 r2:0.5062688589096069\n",
      "epoch72  eval loss:0.00044485312537290156 r2:0.7840368151664734\n",
      "epoch73  eval loss:0.0004629783798009157 r2:0.6485235095024109\n",
      "epoch74  eval loss:0.00046923113404773176 r2:0.6166788935661316\n",
      "epoch75  eval loss:0.00038552889600396156 r2:0.6791079044342041\n",
      "epoch76  eval loss:0.00043321531848050654 r2:0.7640224695205688\n",
      "epoch77  eval loss:0.00043570369598455727 r2:0.7647286653518677\n",
      "epoch78  eval loss:0.0004281246801838279 r2:0.7463659048080444\n",
      "epoch79  eval loss:0.0004406897642184049 r2:0.7717378735542297\n",
      "epoch80  eval loss:0.0004113750474061817 r2:0.7500138282775879\n",
      "epoch81  eval loss:0.0004662268329411745 r2:0.6283098459243774\n",
      "epoch82  eval loss:0.0004187088634353131 r2:0.7643674612045288\n",
      "epoch83  eval loss:0.0004475654859561473 r2:0.7108707427978516\n",
      "epoch84  eval loss:0.0004463506629690528 r2:0.7374221086502075\n",
      "epoch85  eval loss:0.00040331538184545934 r2:0.7835069894790649\n",
      "epoch86  eval loss:0.0004103299288544804 r2:0.7718570232391357\n",
      "epoch87  eval loss:0.00041790035902522504 r2:0.7405135035514832\n",
      "epoch88  eval loss:0.0004162426630500704 r2:0.6750738620758057\n",
      "epoch89  eval loss:0.00040002763853408396 r2:0.7621051073074341\n",
      "epoch90  eval loss:0.0004507686535362154 r2:0.645974338054657\n",
      "epoch91  eval loss:0.00040264110430143774 r2:0.6150041222572327\n",
      "epoch92  eval loss:0.00040342260035686195 r2:0.6959455013275146\n",
      "epoch93  eval loss:0.00044289533980190754 r2:0.6504858732223511\n",
      "epoch94  eval loss:0.0004117160860914737 r2:0.7732608318328857\n",
      "epoch95  eval loss:0.0003933575935661793 r2:0.7757121324539185\n",
      "epoch96  eval loss:0.0003708380972966552 r2:0.8001629710197449\n",
      "epoch97  eval loss:0.0003989981487393379 r2:0.7869551181793213\n",
      "epoch98  eval loss:0.0004226269666105509 r2:0.6695677638053894\n",
      "epoch99  eval loss:0.00043063765042461455 r2:0.7226207256317139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)\n",
    "\n",
    "ns_ls=[16,32,64]\n",
    "dataset=NomalCo2Dataset_loadALL(\"./target_task/data_normal\")\n",
    "lr=0.001\n",
    "for ns in ns_ls:\n",
    "    print(f\"-----------------------------------------normalloss_mse_lr{lr}_ns{ns}---------------------------------------------\")\n",
    "    ns_=63-ns\n",
    "    model_path_normal = f\"./saved_model/normal_fineds_mse_lr{lr}_ns{ns}.pth\"\n",
    "    dataset_i, _= torch.utils.data.random_split(dataset, [ns, ns_])\n",
    "    model = build_resunetplusplus()\n",
    "    model = model.to(DEVICE)\n",
    "    loss_normal=normal_train(model, dataset_i, 0.25, EPOCH, BATCH_SIZE, lr, DEVICE,model_path_normal)\n",
    "    np.savetxt(f\"normalloss_mse_lr{lr}_ns{ns}.csv\",loss_normal,delimiter=',')\n",
    "    plot(loss_normal, [0], f'normalloss_mse_lr{lr}_ns{ns}.png')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    }
   ],
   "source": [
    "normal_loss=np.loadtxt(f\"normalloss_wz5_sc100_lr0.0005_ns16.csv\",loss_normal,delimiter=',')\n",
    "plot(loss_normal, [0], 'normal_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "-------------------------MSE_LR_OUTER0.01--EPOCH_INNER3--------------------------\n",
      "outer_epoch&task0  eval_loss:0.004839874804019928 r2-2.2172040939331055\n",
      "outer_epoch&task1  eval_loss:0.005143705289810896 r2-2.2441720962524414\n",
      "outer_epoch&task2  eval_loss:0.005497944541275501 r2-3.0063037872314453\n",
      "outer_epoch&task3  eval_loss:0.00254303147085011 r2-0.7202330827713013\n",
      "outer_epoch&task4  eval_loss:0.0019430196844041348 r2-0.36383092403411865\n",
      "outer_epoch&task5  eval_loss:0.0013554261531680822 r2-0.12543833255767822\n",
      "outer_epoch&task6  eval_loss:0.0012683873064815998 r2-0.09567487239837646\n",
      "outer_epoch&task7  eval_loss:0.0016783691244199872 r2-0.05817866325378418\n",
      "outer_epoch&task8  eval_loss:0.001464937929995358 r2-0.02856576442718506\n",
      "outer_epoch&task9  eval_loss:0.0015800060937181115 r2-0.051906585693359375\n",
      "outer_epoch&task10  eval_loss:0.0015937252901494503 r2-0.041413307189941406\n",
      "outer_epoch&task11  eval_loss:0.0017258659936487675 r2-0.03890204429626465\n",
      "outer_epoch&task12  eval_loss:0.0013543901732191443 r2-0.09007179737091064\n",
      "outer_epoch&task13  eval_loss:0.0012896229745820165 r2-0.04025745391845703\n",
      "outer_epoch&task14  eval_loss:0.0013955592876300216 r2-0.11866843700408936\n",
      "outer_epoch&task15  eval_loss:0.0014581814175471663 r2-0.0361858606338501\n",
      "outer_epoch&task16  eval_loss:0.001594277797266841 r2-0.041971564292907715\n",
      "outer_epoch&task17  eval_loss:0.001606019213795662 r2-0.02793097496032715\n",
      "outer_epoch&task18  eval_loss:0.0015858476981520653 r2-0.025234341621398926\n",
      "outer_epoch&task19  eval_loss:0.0015149051323533058 r2-0.01507258415222168\n",
      "outer_epoch&task20  eval_loss:0.0014924433780834079 r2-0.014479398727416992\n",
      "outer_epoch&task21  eval_loss:0.0014864197000861168 r2-0.0640333890914917\n",
      "outer_epoch&task22  eval_loss:0.0015121144242584705 r2-0.04144883155822754\n",
      "outer_epoch&task23  eval_loss:0.0014364601811394095 r2-0.05814778804779053\n",
      "outer_epoch&task24  eval_loss:0.0013787029311060905 r2-0.03382587432861328\n",
      "outer_epoch&task25  eval_loss:0.001628859550692141 r2-0.01343393325805664\n",
      "outer_epoch&task26  eval_loss:0.0014967587776482105 r2-0.032056331634521484\n",
      "outer_epoch&task27  eval_loss:0.0015479204012081027 r2-0.01902461051940918\n",
      "outer_epoch&task28  eval_loss:0.0013662622077390552 r2-0.03767251968383789\n",
      "outer_epoch&task29  eval_loss:0.0011959647526964545 r2-0.020284652709960938\n",
      "outer_epoch&task30  eval_loss:0.0016571845626458526 r2-0.022442340850830078\n",
      "outer_epoch&task31  eval_loss:0.0013800653396174312 r2-0.012503504753112793\n",
      "outer_epoch&task32  eval_loss:0.0014303168281912804 r2-0.020664095878601074\n",
      "outer_epoch&task33  eval_loss:0.0013755160616710782 r2-0.010159015655517578\n",
      "outer_epoch&task34  eval_loss:0.001291382359340787 r2-0.013673901557922363\n",
      "outer_epoch&task35  eval_loss:0.0010761303128674626 r2-0.057766079902648926\n",
      "outer_epoch&task36  eval_loss:0.0015345903811976314 r2-0.020049452781677246\n",
      "outer_epoch&task37  eval_loss:0.0014307504752650857 r2-0.022126317024230957\n",
      "outer_epoch&task38  eval_loss:0.001155703910626471 r2-0.025141119956970215\n",
      "outer_epoch&task39  eval_loss:0.001369972014799714 r2-0.05010545253753662\n",
      "outer_epoch&task40  eval_loss:0.0012822982389479876 r2-0.030754566192626953\n",
      "outer_epoch&task41  eval_loss:0.0015285243280231953 r2-0.012267112731933594\n",
      "outer_epoch&task42  eval_loss:0.0016345425974577665 r2-0.10315287113189697\n",
      "outer_epoch&task43  eval_loss:0.0013531059958040714 r2-0.09284675121307373\n",
      "outer_epoch&task44  eval_loss:0.0016197190852835774 r2-0.16200125217437744\n",
      "outer_epoch&task45  eval_loss:0.0013713655062019825 r2-0.04811966419219971\n",
      "outer_epoch&task46  eval_loss:0.0013234543148428202 r2-0.06502902507781982\n",
      "outer_epoch&task47  eval_loss:0.0018972510006278753 r2-0.14036893844604492\n",
      "outer_epoch&task48  eval_loss:0.0014645842602476478 r2-0.1691880226135254\n",
      "outer_epoch&task49  eval_loss:0.0016748382477089763 r2-0.03078782558441162\n",
      "outer_epoch&task50  eval_loss:0.0015093135880306363 r2-0.03285253047943115\n",
      "outer_epoch&task51  eval_loss:0.0014073231723159552 r2-0.05320572853088379\n",
      "outer_epoch&task52  eval_loss:0.001585393212735653 r2-0.02821171283721924\n",
      "outer_epoch&task53  eval_loss:0.0015735207125544548 r2-0.032805681228637695\n",
      "outer_epoch&task54  eval_loss:0.001784119289368391 r2-0.037447333335876465\n",
      "outer_epoch&task55  eval_loss:0.0012308263685554266 r2-0.015020251274108887\n",
      "outer_epoch&task56  eval_loss:0.0015137242153286934 r2-0.01285851001739502\n",
      "outer_epoch&task57  eval_loss:0.0015321426326408982 r2-0.017841219902038574\n",
      "outer_epoch&task58  eval_loss:0.0014987160684540868 r2-0.04725337028503418\n",
      "outer_epoch&task59  eval_loss:0.0012273082975298166 r2-0.014785170555114746\n",
      "outer_epoch&task60  eval_loss:0.0010473703732714057 r2-0.024225950241088867\n",
      "outer_epoch&task61  eval_loss:0.001637161010876298 r2-0.0058803558349609375\n",
      "outer_epoch&task62  eval_loss:0.0014800105709582567 r2-0.010026693344116211\n",
      "outer_epoch&task63  eval_loss:0.0014372539008036256 r2-0.011266589164733887\n",
      "outer_epoch&task64  eval_loss:0.0016677120001986623 r2-0.009047746658325195\n",
      "outer_epoch&task65  eval_loss:0.0013408856466412544 r2-0.031134724617004395\n",
      "outer_epoch&task66  eval_loss:0.0017264835769310594 r2-0.014132857322692871\n",
      "outer_epoch&task67  eval_loss:0.0014640986919403076 r2-0.005428314208984375\n",
      "outer_epoch&task68  eval_loss:0.001232206472195685 r2-0.0003408193588256836\n",
      "outer_epoch&task69  eval_loss:0.0013538494240492582 r20.0011092424392700195\n",
      "outer_epoch&task70  eval_loss:0.001658471766859293 r20.0017905831336975098\n",
      "outer_epoch&task71  eval_loss:0.0012292892206460238 r2-0.0017904043197631836\n",
      "outer_epoch&task72  eval_loss:0.001216142438352108 r2-0.0034172534942626953\n",
      "outer_epoch&task73  eval_loss:0.0015520986635237932 r2-0.004767060279846191\n",
      "outer_epoch&task74  eval_loss:0.0012048004427924752 r2-0.009679317474365234\n",
      "outer_epoch&task75  eval_loss:0.0015821931883692741 r2-0.001695871353149414\n",
      "outer_epoch&task76  eval_loss:0.0014156842371448874 r20.0028456449508666992\n",
      "outer_epoch&task77  eval_loss:0.001386696589179337 r20.002004563808441162\n",
      "outer_epoch&task78  eval_loss:0.0013187925796955824 r2-0.003034234046936035\n",
      "outer_epoch&task79  eval_loss:0.0013343853643164039 r20.005272924900054932\n",
      "outer_epoch&task80  eval_loss:0.001403613481670618 r20.002965569496154785\n",
      "outer_epoch&task81  eval_loss:0.001194485230371356 r2-0.009029626846313477\n",
      "outer_epoch&task82  eval_loss:0.0014091575285419822 r20.005386769771575928\n",
      "outer_epoch&task83  eval_loss:0.0014728435780853033 r20.003810405731201172\n",
      "outer_epoch&task84  eval_loss:0.0012798982206732035 r20.0010491013526916504\n",
      "outer_epoch&task85  eval_loss:0.001717607257887721 r20.009453356266021729\n",
      "outer_epoch&task86  eval_loss:0.0014300717739388347 r20.006897091865539551\n",
      "outer_epoch&task87  eval_loss:0.0013866850640624762 r2-0.019703388214111328\n",
      "outer_epoch&task88  eval_loss:0.0015267918352037668 r2-0.023250818252563477\n",
      "outer_epoch&task89  eval_loss:0.0014036271022632718 r20.003768742084503174\n",
      "outer_epoch&task90  eval_loss:0.001597777009010315 r20.008222460746765137\n",
      "outer_epoch&task91  eval_loss:0.0016715065576136112 r2-0.005302548408508301\n",
      "outer_epoch&task92  eval_loss:0.0015511433593928814 r2-0.03847825527191162\n",
      "outer_epoch&task93  eval_loss:0.0015375296352431178 r2-0.04432511329650879\n",
      "outer_epoch&task94  eval_loss:0.0015136557631194592 r2-0.028086185455322266\n",
      "outer_epoch&task95  eval_loss:0.0014872190076857805 r2-0.01737070083618164\n",
      "outer_epoch&task96  eval_loss:0.0015254493337124586 r2-0.02520465850830078\n",
      "outer_epoch&task97  eval_loss:0.0014538674149662256 r2-0.05637621879577637\n",
      "outer_epoch&task98  eval_loss:0.0016171556198969483 r2-0.020644664764404297\n",
      "outer_epoch&task99  eval_loss:0.0012739504454657435 r2-0.049252867698669434\n",
      "outer_epoch&task100  eval_loss:0.0013908867258578539 r2-0.06263017654418945\n",
      "outer_epoch&task101  eval_loss:0.001409884192980826 r2-0.007060408592224121\n",
      "outer_epoch&task102  eval_loss:0.0015296722995117307 r2-0.0004705190658569336\n",
      "outer_epoch&task103  eval_loss:0.0015181188937276602 r2-0.0010242462158203125\n",
      "outer_epoch&task104  eval_loss:0.0015400295378640294 r20.0031989216804504395\n",
      "outer_epoch&task105  eval_loss:0.0014313641004264355 r20.005955517292022705\n",
      "outer_epoch&task106  eval_loss:0.001630387268960476 r20.0023236870765686035\n",
      "outer_epoch&task107  eval_loss:0.0013525404501706362 r20.004647374153137207\n",
      "outer_epoch&task108  eval_loss:0.0012589935213327408 r20.0014935731887817383\n",
      "outer_epoch&task109  eval_loss:0.0012545203790068626 r2-0.007001519203186035\n",
      "outer_epoch&task110  eval_loss:0.0014705968787893653 r20.004969537258148193\n",
      "outer_epoch&task111  eval_loss:0.0009726513526402414 r20.0008146762847900391\n",
      "outer_epoch&task112  eval_loss:0.0011448977747932076 r20.0031149983406066895\n",
      "outer_epoch&task113  eval_loss:0.0016525423852726817 r20.005002140998840332\n",
      "outer_epoch&task114  eval_loss:0.0013661356642842293 r20.005614042282104492\n",
      "outer_epoch&task115  eval_loss:0.0016973543679341674 r20.008979320526123047\n",
      "outer_epoch&task116  eval_loss:0.0015634892042726278 r20.007197558879852295\n",
      "outer_epoch&task117  eval_loss:0.0012984813656657934 r2-0.0011655092239379883\n",
      "outer_epoch&task118  eval_loss:0.001400334876962006 r20.0054177045822143555\n",
      "outer_epoch&task119  eval_loss:0.0013821216998621821 r20.004258275032043457\n",
      "outer_epoch&task120  eval_loss:0.001461187144741416 r20.00751185417175293\n",
      "outer_epoch&task121  eval_loss:0.0015984668862074614 r20.0058980584144592285\n",
      "outer_epoch&task122  eval_loss:0.001327809877693653 r20.007025778293609619\n",
      "outer_epoch&task123  eval_loss:0.0016467857640236616 r20.00590592622756958\n",
      "outer_epoch&task124  eval_loss:0.0015491907251998782 r29.453296661376953e-05\n",
      "outer_epoch&task125  eval_loss:0.0013940348289906979 r20.003657102584838867\n",
      "outer_epoch&task126  eval_loss:0.0015273181488737464 r20.007118403911590576\n",
      "outer_epoch&task127  eval_loss:0.0015337012009695172 r20.0027340054512023926\n",
      "outer_epoch&task128  eval_loss:0.0013528524432331324 r20.003667891025543213\n",
      "outer_epoch&task129  eval_loss:0.0013044234365224838 r20.006130397319793701\n",
      "outer_epoch&task130  eval_loss:0.0014518084935843945 r20.008407235145568848\n",
      "outer_epoch&task131  eval_loss:0.00147427327465266 r20.007167160511016846\n",
      "outer_epoch&task132  eval_loss:0.0013015848817303777 r20.0055280327796936035\n",
      "outer_epoch&task133  eval_loss:0.0012737091165035963 r20.0021591782569885254\n",
      "outer_epoch&task134  eval_loss:0.0012950124219059944 r20.003695249557495117\n",
      "outer_epoch&task135  eval_loss:0.0011996179819107056 r20.0049574971199035645\n",
      "outer_epoch&task136  eval_loss:0.0014722751220688224 r2-0.002212047576904297\n",
      "outer_epoch&task137  eval_loss:0.0013782859314233065 r20.005999445915222168\n",
      "outer_epoch&task138  eval_loss:0.0013198874657973647 r20.007154643535614014\n",
      "outer_epoch&task139  eval_loss:0.0017819965723901987 r2-0.008797764778137207\n",
      "outer_epoch&task140  eval_loss:0.0011061773402616382 r2-0.0029186010360717773\n",
      "outer_epoch&task141  eval_loss:0.00168998958542943 r20.00454789400100708\n",
      "outer_epoch&task142  eval_loss:0.0013266728492453694 r2-0.009871482849121094\n",
      "outer_epoch&task143  eval_loss:0.001419051899574697 r2-0.0052530765533447266\n",
      "outer_epoch&task144  eval_loss:0.0016059785848483443 r2-0.02495419979095459\n",
      "outer_epoch&task145  eval_loss:0.0015376294031739235 r2-0.024474501609802246\n",
      "outer_epoch&task146  eval_loss:0.0014829550636932254 r2-0.0429842472076416\n",
      "outer_epoch&task147  eval_loss:0.0014041158137843013 r2-0.026144862174987793\n",
      "outer_epoch&task148  eval_loss:0.0015106070786714554 r2-0.06943404674530029\n",
      "outer_epoch&task149  eval_loss:0.001649052370339632 r2-0.01602315902709961\n",
      "0.00276111\n",
      "-------------------------MSE_LR_OUTER0.001--EPOCH_INNER3--------------------------\n",
      "outer_epoch&task0  eval_loss:0.00812463741749525 r2-4.128359794616699\n",
      "outer_epoch&task1  eval_loss:0.0020943130366504192 r2-0.6961028575897217\n",
      "outer_epoch&task2  eval_loss:0.004158847499638796 r2-1.760178804397583\n",
      "outer_epoch&task3  eval_loss:0.0033668172545731068 r2-1.5577588081359863\n",
      "outer_epoch&task4  eval_loss:0.0023356680758297443 r2-0.648788571357727\n",
      "outer_epoch&task5  eval_loss:0.0016897122841328382 r2-0.2617480754852295\n",
      "outer_epoch&task6  eval_loss:0.0031689682509750128 r2-1.0266857147216797\n",
      "outer_epoch&task7  eval_loss:0.0027039027772843838 r2-0.9995054006576538\n",
      "outer_epoch&task8  eval_loss:0.0038074704352766275 r2-2.170034646987915\n",
      "outer_epoch&task9  eval_loss:0.0033430347684770823 r2-1.0462658405303955\n",
      "outer_epoch&task10  eval_loss:0.0017765307566151023 r2-0.13122022151947021\n",
      "outer_epoch&task11  eval_loss:0.0026618954725563526 r2-0.882975697517395\n",
      "outer_epoch&task12  eval_loss:0.0019467815291136503 r2-0.23941123485565186\n",
      "outer_epoch&task13  eval_loss:0.0019620233215391636 r2-0.49759435653686523\n",
      "outer_epoch&task14  eval_loss:0.002221771515905857 r2-0.3850744962692261\n",
      "outer_epoch&task15  eval_loss:0.002859896281734109 r2-0.9791250228881836\n",
      "outer_epoch&task16  eval_loss:0.0025279491674154997 r2-0.793674111366272\n",
      "outer_epoch&task17  eval_loss:0.0018642679788172245 r2-0.48959600925445557\n",
      "outer_epoch&task18  eval_loss:0.002038601553067565 r2-0.19621634483337402\n",
      "outer_epoch&task19  eval_loss:0.0019769426435232162 r2-0.7032362222671509\n",
      "outer_epoch&task20  eval_loss:0.001797878765501082 r2-0.1788705587387085\n",
      "outer_epoch&task21  eval_loss:0.002691596746444702 r2-0.6408965587615967\n",
      "outer_epoch&task22  eval_loss:0.0018066124757751822 r2-0.278157114982605\n",
      "outer_epoch&task23  eval_loss:0.001606971607543528 r2-0.14825809001922607\n",
      "outer_epoch&task24  eval_loss:0.0013578254729509354 r2-0.11752200126647949\n",
      "outer_epoch&task25  eval_loss:0.002046592766419053 r2-0.6768378019332886\n",
      "outer_epoch&task26  eval_loss:0.0019207469886168838 r2-0.42425811290740967\n",
      "outer_epoch&task27  eval_loss:0.0019987639971077442 r2-0.3929675817489624\n",
      "outer_epoch&task28  eval_loss:0.002071385271847248 r2-0.37001311779022217\n",
      "outer_epoch&task29  eval_loss:0.0016321716830134392 r2-0.2306274175643921\n",
      "outer_epoch&task30  eval_loss:0.0030127428472042084 r2-0.9314861297607422\n",
      "outer_epoch&task31  eval_loss:0.001802817452698946 r2-0.2821927070617676\n",
      "outer_epoch&task32  eval_loss:0.0019444974604994059 r2-0.21191465854644775\n",
      "outer_epoch&task33  eval_loss:0.0020441862288862467 r2-0.577933669090271\n",
      "outer_epoch&task34  eval_loss:0.0020077372901141644 r2-0.24875617027282715\n",
      "outer_epoch&task35  eval_loss:0.001924679963849485 r2-0.2223440408706665\n",
      "outer_epoch&task36  eval_loss:0.0014868768630549312 r2-0.11485123634338379\n",
      "outer_epoch&task37  eval_loss:0.0014021636452525854 r2-0.09493672847747803\n",
      "outer_epoch&task38  eval_loss:0.0032819637563079596 r2-0.9487310647964478\n",
      "outer_epoch&task39  eval_loss:0.0017599232960492373 r2-0.20466148853302002\n",
      "outer_epoch&task40  eval_loss:0.0017201189184561372 r2-0.14098966121673584\n",
      "outer_epoch&task41  eval_loss:0.001514803501777351 r2-0.10818731784820557\n",
      "outer_epoch&task42  eval_loss:0.0017096961382776499 r2-0.08546733856201172\n",
      "outer_epoch&task43  eval_loss:0.0015708612045273185 r2-0.07868516445159912\n",
      "outer_epoch&task44  eval_loss:0.0015103199984878302 r2-0.2513312101364136\n",
      "outer_epoch&task45  eval_loss:0.0015756945358589292 r2-0.2715510129928589\n",
      "outer_epoch&task46  eval_loss:0.0015568530652672052 r2-0.15830576419830322\n",
      "outer_epoch&task47  eval_loss:0.0016985011752694845 r2-0.06383693218231201\n",
      "outer_epoch&task48  eval_loss:0.0015882649458944798 r2-0.14567077159881592\n",
      "outer_epoch&task49  eval_loss:0.0017740641487762332 r2-0.1664736270904541\n",
      "outer_epoch&task50  eval_loss:0.0018372178310528398 r2-0.24168801307678223\n",
      "outer_epoch&task51  eval_loss:0.0016422433545812964 r2-0.13590455055236816\n",
      "outer_epoch&task52  eval_loss:0.0019361587474122643 r2-0.03500032424926758\n",
      "outer_epoch&task53  eval_loss:0.0017220046138390899 r2-0.2214958667755127\n",
      "outer_epoch&task54  eval_loss:0.0017858974169939756 r2-0.21794641017913818\n",
      "outer_epoch&task55  eval_loss:0.0016115664038807154 r2-0.15845882892608643\n",
      "outer_epoch&task56  eval_loss:0.001741468207910657 r2-0.24501633644104004\n",
      "outer_epoch&task57  eval_loss:0.00168301269877702 r2-0.19506633281707764\n",
      "outer_epoch&task58  eval_loss:0.0019357745768502355 r2-0.1511838436126709\n",
      "outer_epoch&task59  eval_loss:0.001656751031987369 r2-0.2378607988357544\n",
      "outer_epoch&task60  eval_loss:0.0016262780409306288 r2-0.13148987293243408\n",
      "outer_epoch&task61  eval_loss:0.0016556165646761656 r2-0.1816021203994751\n",
      "outer_epoch&task62  eval_loss:0.0015655935276299715 r2-0.27571606636047363\n",
      "outer_epoch&task63  eval_loss:0.0018278692150488496 r2-0.3791600465774536\n",
      "outer_epoch&task64  eval_loss:0.0015227283583953977 r2-0.321724534034729\n",
      "outer_epoch&task65  eval_loss:0.001887227175757289 r2-0.32623744010925293\n",
      "outer_epoch&task66  eval_loss:0.001674428815022111 r2-0.14221251010894775\n",
      "outer_epoch&task67  eval_loss:0.001489586429670453 r2-0.09624028205871582\n",
      "outer_epoch&task68  eval_loss:0.0014516649534925818 r2-0.1314791440963745\n",
      "outer_epoch&task69  eval_loss:0.0016691017663106322 r2-0.14098715782165527\n",
      "outer_epoch&task70  eval_loss:0.0018753816839307547 r2-0.2792470455169678\n",
      "outer_epoch&task71  eval_loss:0.0013474624138325453 r2-0.0477215051651001\n",
      "outer_epoch&task72  eval_loss:0.0016018522437661886 r2-0.08396351337432861\n",
      "outer_epoch&task73  eval_loss:0.0016363932518288493 r2-0.2944451570510864\n",
      "outer_epoch&task74  eval_loss:0.0017457581125199795 r2-0.18738853931427002\n",
      "outer_epoch&task75  eval_loss:0.0016372832469642162 r2-0.06162393093109131\n",
      "outer_epoch&task76  eval_loss:0.001332312822341919 r2-0.1369004249572754\n",
      "outer_epoch&task77  eval_loss:0.0016397264553233981 r2-0.21597051620483398\n",
      "outer_epoch&task78  eval_loss:0.0018556626746430993 r2-0.18603241443634033\n",
      "outer_epoch&task79  eval_loss:0.0016735406825318933 r2-0.1620185375213623\n",
      "outer_epoch&task80  eval_loss:0.0018079994479194283 r2-0.1556413173675537\n",
      "outer_epoch&task81  eval_loss:0.0018139745807275176 r2-0.1805790662765503\n",
      "outer_epoch&task82  eval_loss:0.0017875083722174168 r2-0.20129382610321045\n",
      "outer_epoch&task83  eval_loss:0.001826683757826686 r2-0.20359206199645996\n",
      "outer_epoch&task84  eval_loss:0.0019159771036356688 r2-0.09182417392730713\n",
      "outer_epoch&task85  eval_loss:0.0015836098464205861 r2-0.21883869171142578\n",
      "outer_epoch&task86  eval_loss:0.001756137702614069 r2-0.216957688331604\n",
      "outer_epoch&task87  eval_loss:0.001277442555874586 r2-0.1752856969833374\n",
      "outer_epoch&task88  eval_loss:0.0017643001629039645 r2-0.22643661499023438\n",
      "outer_epoch&task89  eval_loss:0.001664301147684455 r2-0.18080508708953857\n",
      "outer_epoch&task90  eval_loss:0.001801774138584733 r2-0.12575721740722656\n",
      "outer_epoch&task91  eval_loss:0.0014370434219017625 r2-0.09348440170288086\n",
      "outer_epoch&task92  eval_loss:0.0015684382524341345 r2-0.07249200344085693\n",
      "outer_epoch&task93  eval_loss:0.0016525668324902654 r2-0.14807021617889404\n",
      "outer_epoch&task94  eval_loss:0.0018974331906065345 r2-0.18071341514587402\n",
      "outer_epoch&task95  eval_loss:0.0017032428877428174 r2-0.1241145133972168\n",
      "outer_epoch&task96  eval_loss:0.0015780975809320807 r2-0.11548399925231934\n",
      "outer_epoch&task97  eval_loss:0.0018659112975001335 r2-0.11423361301422119\n",
      "outer_epoch&task98  eval_loss:0.0017243389738723636 r2-0.20980823040008545\n",
      "outer_epoch&task99  eval_loss:0.0014730134280398488 r2-0.12056446075439453\n",
      "outer_epoch&task100  eval_loss:0.0016269049374386668 r2-0.11108052730560303\n",
      "outer_epoch&task101  eval_loss:0.0016138048376888037 r2-0.20802903175354004\n",
      "outer_epoch&task102  eval_loss:0.0016502455109730363 r2-0.14836883544921875\n",
      "outer_epoch&task103  eval_loss:0.001814342336729169 r2-0.1409165859222412\n",
      "outer_epoch&task104  eval_loss:0.0017190045909956098 r2-0.10836648941040039\n",
      "outer_epoch&task105  eval_loss:0.001684521441347897 r2-0.13871312141418457\n",
      "outer_epoch&task106  eval_loss:0.001744897454045713 r2-0.12508976459503174\n",
      "outer_epoch&task107  eval_loss:0.0015877358382567763 r2-0.0743173360824585\n",
      "outer_epoch&task108  eval_loss:0.0015584236243739724 r2-0.15092575550079346\n",
      "outer_epoch&task109  eval_loss:0.00158898055087775 r2-0.15992343425750732\n",
      "outer_epoch&task110  eval_loss:0.0018081740709021688 r2-0.11740338802337646\n",
      "outer_epoch&task111  eval_loss:0.0013066501123830676 r2-0.1317077875137329\n",
      "outer_epoch&task112  eval_loss:0.0019457185408100486 r2-0.14301395416259766\n",
      "outer_epoch&task113  eval_loss:0.0017146917525678873 r2-0.11374533176422119\n",
      "outer_epoch&task114  eval_loss:0.0016996210906654596 r2-0.17323052883148193\n",
      "outer_epoch&task115  eval_loss:0.001562814344651997 r2-0.11496984958648682\n",
      "outer_epoch&task116  eval_loss:0.001763826236128807 r2-0.1369938850402832\n",
      "outer_epoch&task117  eval_loss:0.001616057357750833 r2-0.22105753421783447\n",
      "outer_epoch&task118  eval_loss:0.0017332768766209483 r2-0.09277665615081787\n",
      "outer_epoch&task119  eval_loss:0.001702489098533988 r2-0.10349118709564209\n",
      "outer_epoch&task120  eval_loss:0.0013463626382872462 r2-0.03528261184692383\n",
      "outer_epoch&task121  eval_loss:0.0017207702621817589 r2-0.39967799186706543\n",
      "outer_epoch&task122  eval_loss:0.0021813714411109686 r2-0.573063850402832\n",
      "outer_epoch&task123  eval_loss:0.0024211760610342026 r2-0.617510199546814\n",
      "outer_epoch&task124  eval_loss:0.0019774651154875755 r2-0.1392883062362671\n",
      "outer_epoch&task125  eval_loss:0.0017078355886042118 r2-0.19216084480285645\n",
      "outer_epoch&task126  eval_loss:0.002616084646433592 r2-0.5167632102966309\n",
      "outer_epoch&task127  eval_loss:0.0022597755305469036 r2-0.47218120098114014\n",
      "outer_epoch&task128  eval_loss:0.0018634978914633393 r2-0.4734222888946533\n",
      "outer_epoch&task129  eval_loss:0.0017755727749317884 r2-0.420407772064209\n",
      "outer_epoch&task130  eval_loss:0.0023662750609219074 r2-0.5208067893981934\n",
      "outer_epoch&task131  eval_loss:0.0022696524392813444 r2-0.7188169956207275\n",
      "outer_epoch&task132  eval_loss:0.0018133638659492135 r2-0.21782422065734863\n",
      "outer_epoch&task133  eval_loss:0.002501869574189186 r2-0.5801378488540649\n",
      "outer_epoch&task134  eval_loss:0.002479197923094034 r2-0.7027504444122314\n",
      "outer_epoch&task135  eval_loss:0.002287571784108877 r2-0.5834025144577026\n",
      "outer_epoch&task136  eval_loss:0.0021795316133648157 r2-0.3482210636138916\n",
      "outer_epoch&task137  eval_loss:0.0018172304844483733 r2-0.5602554082870483\n",
      "outer_epoch&task138  eval_loss:0.002178880153223872 r2-0.3667263984680176\n",
      "outer_epoch&task139  eval_loss:0.0017618994461372495 r2-0.44233036041259766\n",
      "outer_epoch&task140  eval_loss:0.0016327218618243933 r2-0.19998931884765625\n",
      "outer_epoch&task141  eval_loss:0.002213633619248867 r2-0.6087888479232788\n",
      "outer_epoch&task142  eval_loss:0.002245834330096841 r2-0.8487296104431152\n",
      "outer_epoch&task143  eval_loss:0.0021960025187581778 r2-0.5251396894454956\n",
      "outer_epoch&task144  eval_loss:0.001953482860699296 r2-0.5307909250259399\n",
      "outer_epoch&task145  eval_loss:0.0018675478640943766 r2-0.36122310161590576\n",
      "outer_epoch&task146  eval_loss:0.0022748704068362713 r2-0.4828146696090698\n",
      "outer_epoch&task147  eval_loss:0.0024469816125929356 r2-0.6250995397567749\n",
      "outer_epoch&task148  eval_loss:0.0014425928238779306 r2-0.1572667360305786\n",
      "outer_epoch&task149  eval_loss:0.002196479355916381 r2-0.3454846143722534\n",
      "0.0061006853\n",
      "-------------------------MSE_LR_OUTER0.0001--EPOCH_INNER3--------------------------\n",
      "outer_epoch&task0  eval_loss:0.0024320485536009073 r2-0.6527881622314453\n",
      "outer_epoch&task1  eval_loss:0.0017128746258094907 r2-0.2941986322402954\n",
      "outer_epoch&task2  eval_loss:0.0026853301096707582 r2-1.2749404907226562\n",
      "outer_epoch&task3  eval_loss:0.0024124127812683582 r2-1.0725576877593994\n",
      "outer_epoch&task4  eval_loss:0.0057067181915044785 r2-3.6441736221313477\n",
      "outer_epoch&task5  eval_loss:0.003439666936174035 r2-0.9412292242050171\n",
      "outer_epoch&task6  eval_loss:0.002034551929682493 r2-0.3694683313369751\n",
      "outer_epoch&task7  eval_loss:0.0020281190518289804 r2-0.35391390323638916\n",
      "outer_epoch&task8  eval_loss:0.007635252084583044 r2-4.289214134216309\n",
      "outer_epoch&task9  eval_loss:0.0020723058842122555 r2-0.6342594623565674\n",
      "outer_epoch&task10  eval_loss:0.0017127327155321836 r2-0.11214351654052734\n",
      "outer_epoch&task11  eval_loss:0.0015256789047271013 r2-0.16738951206207275\n",
      "outer_epoch&task12  eval_loss:0.001652493025176227 r2-0.22317016124725342\n",
      "outer_epoch&task13  eval_loss:0.001495915581472218 r2-0.1173938512802124\n",
      "outer_epoch&task14  eval_loss:0.001434449222870171 r2-0.05138683319091797\n",
      "outer_epoch&task15  eval_loss:0.0018894871463999152 r2-0.14378416538238525\n",
      "outer_epoch&task16  eval_loss:0.001923649339005351 r2-0.16286325454711914\n",
      "outer_epoch&task17  eval_loss:0.006038694642484188 r2-4.445786476135254\n",
      "outer_epoch&task18  eval_loss:0.0021773064509034157 r2-0.7426495552062988\n",
      "outer_epoch&task19  eval_loss:0.002582992659881711 r2-1.0103759765625\n",
      "outer_epoch&task20  eval_loss:0.0022451195400208235 r2-0.8751621246337891\n",
      "outer_epoch&task21  eval_loss:0.001470241229981184 r2-0.14922213554382324\n",
      "outer_epoch&task22  eval_loss:0.0018715093610808253 r2-0.5460596084594727\n",
      "outer_epoch&task23  eval_loss:0.0035094076301902533 r2-1.3035590648651123\n",
      "outer_epoch&task24  eval_loss:0.004839572124183178 r2-2.1037540435791016\n",
      "outer_epoch&task25  eval_loss:0.001630942220799625 r2-0.12809669971466064\n",
      "outer_epoch&task26  eval_loss:0.001574208028614521 r2-0.0226060152053833\n",
      "outer_epoch&task27  eval_loss:0.0014938029926270247 r2-0.03996539115905762\n",
      "outer_epoch&task28  eval_loss:0.0022438347805291414 r2-0.6184273958206177\n",
      "outer_epoch&task29  eval_loss:0.0014633270911872387 r2-0.11113309860229492\n",
      "outer_epoch&task30  eval_loss:0.002439043950289488 r2-0.5815412998199463\n",
      "outer_epoch&task31  eval_loss:0.0018895852845162153 r2-0.23369979858398438\n",
      "outer_epoch&task32  eval_loss:0.0014809515560045838 r2-0.014058470726013184\n",
      "outer_epoch&task33  eval_loss:0.0022727283649146557 r2-0.6208436489105225\n",
      "outer_epoch&task34  eval_loss:0.0014449377777054906 r2-0.05985677242279053\n",
      "outer_epoch&task35  eval_loss:0.00157453422434628 r2-0.10746991634368896\n",
      "outer_epoch&task36  eval_loss:0.0015982429031282663 r2-0.13377130031585693\n",
      "outer_epoch&task37  eval_loss:0.0014171428047120571 r2-0.14376187324523926\n",
      "outer_epoch&task38  eval_loss:0.0026733463164418936 r2-0.782091498374939\n",
      "outer_epoch&task39  eval_loss:0.001686323550529778 r2-0.21862304210662842\n",
      "outer_epoch&task40  eval_loss:0.0019317426485940814 r2-0.6091287136077881\n",
      "outer_epoch&task41  eval_loss:0.0026868884451687336 r2-0.6293289661407471\n",
      "outer_epoch&task42  eval_loss:0.0026288959197700024 r2-0.8107970952987671\n",
      "outer_epoch&task43  eval_loss:0.0023464993573725224 r2-0.5509244203567505\n",
      "outer_epoch&task44  eval_loss:0.002314687939360738 r2-0.4649200439453125\n",
      "outer_epoch&task45  eval_loss:0.0025351508520543575 r2-0.65302574634552\n",
      "outer_epoch&task46  eval_loss:0.0021877700928598642 r2-0.6112073659896851\n",
      "outer_epoch&task47  eval_loss:0.0017686629435047507 r2-0.06534254550933838\n",
      "outer_epoch&task48  eval_loss:0.001608008285984397 r2-0.04908633232116699\n",
      "outer_epoch&task49  eval_loss:0.001321096671745181 r2-0.03731429576873779\n",
      "outer_epoch&task50  eval_loss:0.0015723507385700941 r2-0.04226088523864746\n",
      "outer_epoch&task51  eval_loss:0.0016029496910050511 r2-0.03939688205718994\n",
      "outer_epoch&task52  eval_loss:0.0016129420837387443 r2-0.0465998649597168\n",
      "outer_epoch&task53  eval_loss:0.002223186893388629 r2-0.5969170331954956\n",
      "outer_epoch&task54  eval_loss:0.002149673644453287 r2-0.4806520938873291\n",
      "outer_epoch&task55  eval_loss:0.0019294152734801173 r2-0.35067760944366455\n",
      "outer_epoch&task56  eval_loss:0.0019471554551273584 r2-0.4787951707839966\n",
      "outer_epoch&task57  eval_loss:0.0023036536294966936 r2-0.3173654079437256\n",
      "outer_epoch&task58  eval_loss:0.0014404437970370054 r2-0.010367870330810547\n",
      "outer_epoch&task59  eval_loss:0.0016204515704885125 r2-0.0224379301071167\n",
      "outer_epoch&task60  eval_loss:0.001809668610803783 r2-0.2676612138748169\n",
      "outer_epoch&task61  eval_loss:0.0016074148006737232 r2-0.023563504219055176\n",
      "outer_epoch&task62  eval_loss:0.0011528423056006432 r2-0.054107666015625\n",
      "outer_epoch&task63  eval_loss:0.0016238810494542122 r2-0.05752754211425781\n",
      "outer_epoch&task64  eval_loss:0.0016587130958214402 r2-0.33208394050598145\n",
      "outer_epoch&task65  eval_loss:0.0018026642501354218 r2-0.24358713626861572\n",
      "outer_epoch&task66  eval_loss:0.0016227844171226025 r2-0.17920148372650146\n",
      "outer_epoch&task67  eval_loss:0.0018484445754438639 r2-0.3551025390625\n",
      "outer_epoch&task68  eval_loss:0.0016568945720791817 r2-0.22991907596588135\n",
      "outer_epoch&task69  eval_loss:0.001682745642028749 r2-0.505229115486145\n",
      "outer_epoch&task70  eval_loss:0.0016699089901521802 r2-0.11021208763122559\n",
      "outer_epoch&task71  eval_loss:0.001862277276813984 r2-0.18213093280792236\n",
      "outer_epoch&task72  eval_loss:0.0016508519183844328 r2-0.14325249195098877\n",
      "outer_epoch&task73  eval_loss:0.0016874555731192231 r2-0.12332653999328613\n",
      "outer_epoch&task74  eval_loss:0.0014268942177295685 r2-0.021986722946166992\n",
      "outer_epoch&task75  eval_loss:0.0016198502853512764 r2-0.07059669494628906\n",
      "outer_epoch&task76  eval_loss:0.0018544452032074332 r2-0.0819239616394043\n",
      "outer_epoch&task77  eval_loss:0.0016239951364696026 r2-0.024338483810424805\n",
      "outer_epoch&task78  eval_loss:0.0013459917390719056 r2-0.08831989765167236\n",
      "outer_epoch&task79  eval_loss:0.0022224057465791702 r2-0.8824117183685303\n",
      "outer_epoch&task80  eval_loss:0.001652008737437427 r2-0.17287099361419678\n",
      "outer_epoch&task81  eval_loss:0.0014347335090860724 r2-0.033666253089904785\n",
      "outer_epoch&task82  eval_loss:0.0015267845010384917 r2-0.03129410743713379\n",
      "outer_epoch&task83  eval_loss:0.0012114988639950752 r2-0.02127695083618164\n",
      "outer_epoch&task84  eval_loss:0.0016963293310254812 r2-0.17566990852355957\n",
      "outer_epoch&task85  eval_loss:0.0015005497261881828 r2-0.028951644897460938\n",
      "outer_epoch&task86  eval_loss:0.0013459500623866916 r2-0.06136190891265869\n",
      "outer_epoch&task87  eval_loss:0.0012325282441452146 r2-0.03442955017089844\n",
      "outer_epoch&task88  eval_loss:0.0012413585791364312 r2-0.04651319980621338\n",
      "outer_epoch&task89  eval_loss:0.001678341068327427 r2-0.1634202003479004\n",
      "outer_epoch&task90  eval_loss:0.0018281610682606697 r2-0.1791844367980957\n",
      "outer_epoch&task91  eval_loss:0.001908801612444222 r2-0.5216683149337769\n",
      "outer_epoch&task92  eval_loss:0.0015852588694542646 r2-0.12889134883880615\n",
      "outer_epoch&task93  eval_loss:0.0014582689618691802 r2-0.11065781116485596\n",
      "outer_epoch&task94  eval_loss:0.0018739700317382812 r2-0.021918535232543945\n",
      "outer_epoch&task95  eval_loss:0.0014439012156799436 r2-0.03160858154296875\n",
      "outer_epoch&task96  eval_loss:0.0014954470098018646 r2-0.05494880676269531\n",
      "outer_epoch&task97  eval_loss:0.0018046963959932327 r2-0.2585378885269165\n",
      "outer_epoch&task98  eval_loss:0.0012406414607539773 r2-0.06782972812652588\n",
      "outer_epoch&task99  eval_loss:0.0017645133193582296 r2-0.2521224021911621\n",
      "outer_epoch&task100  eval_loss:0.0014196097617968917 r2-0.03857874870300293\n",
      "outer_epoch&task101  eval_loss:0.0012819841504096985 r2-0.07520842552185059\n",
      "outer_epoch&task102  eval_loss:0.0015437722904607654 r2-0.009517550468444824\n",
      "outer_epoch&task103  eval_loss:0.001741053070873022 r2-0.258550763130188\n",
      "outer_epoch&task104  eval_loss:0.001688566873781383 r2-0.060027360916137695\n",
      "outer_epoch&task105  eval_loss:0.002044510096311569 r2-0.4589104652404785\n",
      "outer_epoch&task106  eval_loss:0.0019863583147525787 r2-0.26525163650512695\n",
      "outer_epoch&task107  eval_loss:0.0018812984926626086 r2-0.20438635349273682\n",
      "outer_epoch&task108  eval_loss:0.0014205442275851965 r2-0.028815507888793945\n",
      "outer_epoch&task109  eval_loss:0.0014412514865398407 r2-0.04835653305053711\n",
      "outer_epoch&task110  eval_loss:0.0017598444828763604 r2-0.19947409629821777\n",
      "outer_epoch&task111  eval_loss:0.0017196437111124396 r2-0.03996896743774414\n",
      "outer_epoch&task112  eval_loss:0.0014504981227219105 r2-0.13651835918426514\n",
      "outer_epoch&task113  eval_loss:0.001979786204174161 r2-0.25641441345214844\n",
      "outer_epoch&task114  eval_loss:0.0015876657562330365 r2-0.028868556022644043\n",
      "outer_epoch&task115  eval_loss:0.0016918611945584416 r2-0.10375308990478516\n",
      "outer_epoch&task116  eval_loss:0.001577230985276401 r2-0.04986608028411865\n",
      "outer_epoch&task117  eval_loss:0.001670472207479179 r2-0.112548828125\n",
      "outer_epoch&task118  eval_loss:0.0014797018375247717 r2-0.22172129154205322\n",
      "outer_epoch&task119  eval_loss:0.0015211007557809353 r2-0.03357672691345215\n",
      "outer_epoch&task120  eval_loss:0.0016641792608425021 r2-0.15978920459747314\n",
      "outer_epoch&task121  eval_loss:0.0019230159232392907 r2-0.11444282531738281\n",
      "outer_epoch&task122  eval_loss:0.0014611121732741594 r2-0.021681666374206543\n",
      "outer_epoch&task123  eval_loss:0.002139023505151272 r2-0.37057507038116455\n",
      "outer_epoch&task124  eval_loss:0.0018646292155608535 r2-0.2088533639907837\n",
      "outer_epoch&task125  eval_loss:0.001474025659263134 r2-0.07829892635345459\n",
      "outer_epoch&task126  eval_loss:0.0017759883776307106 r2-0.17252767086029053\n",
      "outer_epoch&task127  eval_loss:0.00133144436404109 r2-0.09998035430908203\n",
      "outer_epoch&task128  eval_loss:0.001936736167408526 r2-0.210119366645813\n",
      "outer_epoch&task129  eval_loss:0.0019210092723369598 r2-0.20293021202087402\n",
      "outer_epoch&task130  eval_loss:0.0017494698986411095 r2-0.0060577392578125\n",
      "outer_epoch&task131  eval_loss:0.0017880424857139587 r2-0.026300907135009766\n",
      "outer_epoch&task132  eval_loss:0.0017704516649246216 r2-0.15241003036499023\n",
      "outer_epoch&task133  eval_loss:0.0015247934497892857 r2-0.005600094795227051\n",
      "outer_epoch&task134  eval_loss:0.0014321641065180302 r2-0.12342703342437744\n",
      "outer_epoch&task135  eval_loss:0.001431028707884252 r2-0.02285921573638916\n",
      "outer_epoch&task136  eval_loss:0.0013663975987583399 r2-0.1184229850769043\n",
      "outer_epoch&task137  eval_loss:0.002030559815466404 r2-0.6118137836456299\n",
      "outer_epoch&task138  eval_loss:0.0015231955330818892 r2-0.45045411586761475\n",
      "outer_epoch&task139  eval_loss:0.0019165788544341922 r2-0.021029233932495117\n",
      "outer_epoch&task140  eval_loss:0.0019516440806910396 r2-0.14246821403503418\n",
      "outer_epoch&task141  eval_loss:0.0013336505508050323 r2-0.03156840801239014\n",
      "outer_epoch&task142  eval_loss:0.0014857646310701966 r2-0.08453381061553955\n",
      "outer_epoch&task143  eval_loss:0.0015934413531795144 r2-0.15766620635986328\n",
      "outer_epoch&task144  eval_loss:0.0014923708513379097 r2-0.05076396465301514\n",
      "outer_epoch&task145  eval_loss:0.0014232281828299165 r2-0.07507336139678955\n",
      "outer_epoch&task146  eval_loss:0.0015041256556287408 r2-0.03323483467102051\n",
      "outer_epoch&task147  eval_loss:0.0015236688777804375 r2-0.057105422019958496\n",
      "outer_epoch&task148  eval_loss:0.0016752430237829685 r2-0.13230454921722412\n",
      "outer_epoch&task149  eval_loss:0.001390872523188591 r2-0.0591050386428833\n",
      "0.0052429046\n",
      "-------------------------MSE_LR_OUTER1e-05--EPOCH_INNER3--------------------------\n",
      "outer_epoch&task0  eval_loss:0.0020977600943297148 r2-0.43555283546447754\n",
      "outer_epoch&task1  eval_loss:0.0016315808752551675 r2-0.15005898475646973\n",
      "outer_epoch&task2  eval_loss:0.0018176337471231818 r2-0.09603428840637207\n",
      "outer_epoch&task3  eval_loss:0.002112877555191517 r2-0.34454095363616943\n",
      "outer_epoch&task4  eval_loss:0.001950582955032587 r2-0.30528903007507324\n",
      "outer_epoch&task5  eval_loss:0.0019041948253288865 r2-0.6736352443695068\n",
      "outer_epoch&task6  eval_loss:0.0023402059450745583 r2-0.6732076406478882\n",
      "outer_epoch&task7  eval_loss:0.0019881301559507847 r2-0.25669634342193604\n",
      "outer_epoch&task8  eval_loss:0.0027841622941195965 r2-0.6866294145584106\n",
      "outer_epoch&task9  eval_loss:0.0022296139504760504 r2-0.5024298429489136\n",
      "outer_epoch&task10  eval_loss:0.0025942011270672083 r2-0.9374918937683105\n",
      "outer_epoch&task11  eval_loss:0.002024300629273057 r2-0.5542330741882324\n",
      "outer_epoch&task12  eval_loss:0.0027858209796249866 r2-0.95401930809021\n",
      "outer_epoch&task13  eval_loss:0.002385532483458519 r2-0.7919962406158447\n",
      "outer_epoch&task14  eval_loss:0.0029250257648527622 r2-0.7623279094696045\n",
      "outer_epoch&task15  eval_loss:0.0022137246560305357 r2-0.9004297256469727\n",
      "outer_epoch&task16  eval_loss:0.0027648722752928734 r2-0.8370270729064941\n",
      "outer_epoch&task17  eval_loss:0.0023243133910000324 r2-0.7659519910812378\n",
      "outer_epoch&task18  eval_loss:0.0029752361588180065 r2-1.2230720520019531\n",
      "outer_epoch&task19  eval_loss:0.004100588150322437 r2-2.5331525802612305\n",
      "outer_epoch&task20  eval_loss:0.0031497946474701166 r2-1.587470293045044\n",
      "outer_epoch&task21  eval_loss:0.00421873340383172 r2-1.9512901306152344\n",
      "outer_epoch&task22  eval_loss:0.002904959488660097 r2-1.1376450061798096\n",
      "outer_epoch&task23  eval_loss:0.0027454993687570095 r2-0.9627639055252075\n",
      "outer_epoch&task24  eval_loss:0.00403310963883996 r2-1.620201826095581\n",
      "outer_epoch&task25  eval_loss:0.0038044254761189222 r2-1.4947688579559326\n",
      "outer_epoch&task26  eval_loss:0.0038951262831687927 r2-1.2697622776031494\n",
      "outer_epoch&task27  eval_loss:0.008258137851953506 r2-3.804553508758545\n",
      "outer_epoch&task28  eval_loss:0.005890262313187122 r2-4.477675914764404\n",
      "outer_epoch&task29  eval_loss:0.003933177795261145 r2-2.096848964691162\n",
      "outer_epoch&task30  eval_loss:0.004340778104960918 r2-1.7069401741027832\n",
      "outer_epoch&task31  eval_loss:0.004876651801168919 r2-3.7362446784973145\n",
      "outer_epoch&task32  eval_loss:0.0034761102870106697 r2-1.608565092086792\n",
      "outer_epoch&task33  eval_loss:0.005744098220020533 r2-4.0679802894592285\n",
      "outer_epoch&task34  eval_loss:0.00466109998524189 r2-1.9768164157867432\n",
      "outer_epoch&task35  eval_loss:0.004448573105037212 r2-1.6413018703460693\n",
      "outer_epoch&task36  eval_loss:0.003298570401966572 r2-1.2372395992279053\n",
      "outer_epoch&task37  eval_loss:0.003261927980929613 r2-1.2647836208343506\n",
      "outer_epoch&task38  eval_loss:0.00455121137201786 r2-2.768372058868408\n",
      "outer_epoch&task39  eval_loss:0.004625970032066107 r2-2.3791987895965576\n",
      "outer_epoch&task40  eval_loss:0.006230034865438938 r2-3.439460277557373\n",
      "outer_epoch&task41  eval_loss:0.006365575361996889 r2-3.75117826461792\n",
      "outer_epoch&task42  eval_loss:0.010100629180669785 r2-7.978157997131348\n",
      "outer_epoch&task43  eval_loss:0.006041067652404308 r2-3.4563183784484863\n",
      "outer_epoch&task44  eval_loss:0.006888498552143574 r2-4.00004768371582\n",
      "outer_epoch&task45  eval_loss:0.005878671072423458 r2-3.3833975791931152\n",
      "outer_epoch&task46  eval_loss:0.003740986343473196 r2-1.2457282543182373\n",
      "outer_epoch&task47  eval_loss:0.004574284888803959 r2-2.47704815864563\n",
      "outer_epoch&task48  eval_loss:0.009974149987101555 r2-7.079434394836426\n",
      "outer_epoch&task49  eval_loss:0.00750090554356575 r2-4.837515830993652\n",
      "outer_epoch&task50  eval_loss:0.012519577518105507 r2-7.347756385803223\n",
      "outer_epoch&task51  eval_loss:0.010055947117507458 r2-5.292346000671387\n",
      "outer_epoch&task52  eval_loss:0.010344048030674458 r2-6.192577838897705\n",
      "outer_epoch&task53  eval_loss:0.0054490454494953156 r2-3.269031524658203\n",
      "outer_epoch&task54  eval_loss:0.008513504639267921 r2-4.659054279327393\n",
      "outer_epoch&task55  eval_loss:0.0019948319531977177 r2-0.5295640230178833\n",
      "outer_epoch&task56  eval_loss:0.005337061360478401 r2-2.709629774093628\n",
      "outer_epoch&task57  eval_loss:0.0038641835562884808 r2-1.6505603790283203\n",
      "outer_epoch&task58  eval_loss:0.010381673462688923 r2-6.96963357925415\n",
      "outer_epoch&task59  eval_loss:0.002137676114216447 r2-0.5291459560394287\n",
      "outer_epoch&task60  eval_loss:0.00697185518220067 r2-3.969113826751709\n",
      "outer_epoch&task61  eval_loss:0.004277988336980343 r2-1.9941685199737549\n",
      "outer_epoch&task62  eval_loss:0.0021604462526738644 r2-0.7611105442047119\n",
      "outer_epoch&task63  eval_loss:0.00801901239901781 r2-5.4988555908203125\n",
      "outer_epoch&task64  eval_loss:0.0037271694745868444 r2-1.9322021007537842\n",
      "outer_epoch&task65  eval_loss:0.004380274098366499 r2-1.6654033660888672\n",
      "outer_epoch&task66  eval_loss:0.005398164503276348 r2-2.918989658355713\n",
      "outer_epoch&task67  eval_loss:0.0018342046532779932 r2-0.4644707441329956\n",
      "outer_epoch&task68  eval_loss:0.003899806411936879 r2-1.6452844142913818\n",
      "outer_epoch&task69  eval_loss:0.0017979908734560013 r2-0.4846794605255127\n",
      "outer_epoch&task70  eval_loss:0.001636420376598835 r2-0.36336827278137207\n",
      "outer_epoch&task71  eval_loss:0.001905195415019989 r2-0.22085392475128174\n",
      "outer_epoch&task72  eval_loss:0.002147488296031952 r2-0.6271541118621826\n",
      "outer_epoch&task73  eval_loss:0.002713225083425641 r2-0.8699953556060791\n",
      "outer_epoch&task74  eval_loss:0.0020957496017217636 r2-0.2365638017654419\n",
      "outer_epoch&task75  eval_loss:0.0017430157167837024 r2-0.20836591720581055\n",
      "outer_epoch&task76  eval_loss:0.002120567485690117 r2-0.3814936876296997\n",
      "outer_epoch&task77  eval_loss:0.0018966509960591793 r2-0.20311105251312256\n",
      "outer_epoch&task78  eval_loss:0.0031516943126916885 r2-1.0853123664855957\n",
      "outer_epoch&task79  eval_loss:0.0023728022351861 r2-0.7600568532943726\n",
      "outer_epoch&task80  eval_loss:0.0036878082901239395 r2-1.1985547542572021\n",
      "outer_epoch&task81  eval_loss:0.003599987830966711 r2-1.6018695831298828\n",
      "outer_epoch&task82  eval_loss:0.0020389643032103777 r2-0.6183923482894897\n",
      "outer_epoch&task83  eval_loss:0.002064031781628728 r2-0.5510963201522827\n",
      "outer_epoch&task84  eval_loss:0.009586676023900509 r2-5.726008415222168\n",
      "outer_epoch&task85  eval_loss:0.0038174455985426903 r2-1.5524468421936035\n",
      "outer_epoch&task86  eval_loss:0.002364179352298379 r2-0.9069874286651611\n",
      "outer_epoch&task87  eval_loss:0.0021629962138831615 r2-0.4583481550216675\n",
      "outer_epoch&task88  eval_loss:0.007256924640387297 r2-3.8291988372802734\n",
      "outer_epoch&task89  eval_loss:0.004293826408684254 r2-1.690406322479248\n",
      "outer_epoch&task90  eval_loss:0.0025981487706303596 r2-0.8661757707595825\n",
      "outer_epoch&task91  eval_loss:0.0068597495555877686 r2-4.110478401184082\n",
      "outer_epoch&task92  eval_loss:0.0032512512989342213 r2-1.155968427658081\n",
      "outer_epoch&task93  eval_loss:0.0017036820063367486 r2-0.18118202686309814\n",
      "outer_epoch&task94  eval_loss:0.0030424720607697964 r2-0.9182957410812378\n",
      "outer_epoch&task95  eval_loss:0.0014245959464460611 r2-0.2237870693206787\n",
      "outer_epoch&task96  eval_loss:0.0036806310527026653 r2-1.2281677722930908\n",
      "outer_epoch&task97  eval_loss:0.0028761737048625946 r2-1.0405960083007812\n",
      "outer_epoch&task98  eval_loss:0.008213767781853676 r2-4.363555908203125\n",
      "outer_epoch&task99  eval_loss:0.00645291805267334 r2-3.0799012184143066\n",
      "outer_epoch&task100  eval_loss:0.0017802112270146608 r2-0.36222243309020996\n",
      "outer_epoch&task101  eval_loss:0.006555282976478338 r2-3.381436347961426\n",
      "outer_epoch&task102  eval_loss:0.002123807091265917 r2-0.38154757022857666\n",
      "outer_epoch&task103  eval_loss:0.0032433958258479834 r2-1.093228816986084\n",
      "outer_epoch&task104  eval_loss:0.0021406107116490602 r2-0.45199060440063477\n",
      "outer_epoch&task105  eval_loss:0.0035205241292715073 r2-1.39333176612854\n",
      "outer_epoch&task106  eval_loss:0.008731466718018055 r2-4.527797698974609\n",
      "outer_epoch&task107  eval_loss:0.0031756770331412554 r2-0.8752533197402954\n",
      "outer_epoch&task108  eval_loss:0.0017130447085946798 r2-0.6182105541229248\n",
      "outer_epoch&task109  eval_loss:0.0018955316627398133 r2-0.27510714530944824\n",
      "outer_epoch&task110  eval_loss:0.0023077107034623623 r2-0.6832081079483032\n",
      "outer_epoch&task111  eval_loss:0.002817928558215499 r2-0.9820783138275146\n",
      "outer_epoch&task112  eval_loss:0.006940582767128944 r2-3.75516939163208\n",
      "outer_epoch&task113  eval_loss:0.0035486933775246143 r2-1.1462934017181396\n",
      "outer_epoch&task114  eval_loss:0.003071302780881524 r2-0.9727665185928345\n",
      "outer_epoch&task115  eval_loss:0.0030872959177941084 r2-0.8609528541564941\n",
      "outer_epoch&task116  eval_loss:0.0023121261037886143 r2-0.6643251180648804\n",
      "outer_epoch&task117  eval_loss:0.0018856569658964872 r2-0.26751530170440674\n",
      "outer_epoch&task118  eval_loss:0.0028075966984033585 r2-0.9847708940505981\n",
      "outer_epoch&task119  eval_loss:0.001637528301216662 r2-0.382282018661499\n",
      "outer_epoch&task120  eval_loss:0.002506027463823557 r2-0.7579716444015503\n",
      "outer_epoch&task121  eval_loss:0.002214405220001936 r2-0.4776175022125244\n",
      "outer_epoch&task122  eval_loss:0.0017098907846957445 r2-0.22260785102844238\n",
      "outer_epoch&task123  eval_loss:0.001954388339072466 r2-0.39466917514801025\n",
      "outer_epoch&task124  eval_loss:0.0015297018690034747 r2-0.14056801795959473\n",
      "outer_epoch&task125  eval_loss:0.006084450986236334 r2-3.2176623344421387\n",
      "outer_epoch&task126  eval_loss:0.006055711768567562 r2-2.980740547180176\n",
      "outer_epoch&task127  eval_loss:0.001446464448235929 r2-0.18248343467712402\n",
      "outer_epoch&task128  eval_loss:0.0028052625712007284 r2-0.9281566143035889\n",
      "outer_epoch&task129  eval_loss:0.0025500503834336996 r2-0.8425630331039429\n",
      "outer_epoch&task130  eval_loss:0.0028123948723077774 r2-0.9465622901916504\n",
      "outer_epoch&task131  eval_loss:0.00307347415946424 r2-0.9164348840713501\n",
      "outer_epoch&task132  eval_loss:0.003822755068540573 r2-1.968597412109375\n",
      "outer_epoch&task133  eval_loss:0.0018403055146336555 r2-0.20286059379577637\n",
      "outer_epoch&task134  eval_loss:0.001790469279512763 r2-0.09434843063354492\n",
      "outer_epoch&task135  eval_loss:0.0029188122134655714 r2-0.8176881074905396\n",
      "outer_epoch&task136  eval_loss:0.004345227964222431 r2-2.341803550720215\n",
      "outer_epoch&task137  eval_loss:0.0020131468772888184 r2-0.2274632453918457\n",
      "outer_epoch&task138  eval_loss:0.0015875983517616987 r2-0.07726311683654785\n",
      "outer_epoch&task139  eval_loss:0.007037333212792873 r2-4.492901802062988\n",
      "outer_epoch&task140  eval_loss:0.0016666044248268008 r2-0.3107123374938965\n",
      "outer_epoch&task141  eval_loss:0.0026561683043837547 r2-0.8614509105682373\n",
      "outer_epoch&task142  eval_loss:0.005418733693659306 r2-2.500649929046631\n",
      "outer_epoch&task143  eval_loss:0.0017085872823372483 r2-0.4199265241622925\n",
      "outer_epoch&task144  eval_loss:0.0016818655421957374 r2-0.28922510147094727\n",
      "outer_epoch&task145  eval_loss:0.003274186048656702 r2-1.07362699508667\n",
      "outer_epoch&task146  eval_loss:0.0035017789341509342 r2-1.3979051113128662\n",
      "outer_epoch&task147  eval_loss:0.0037492108531296253 r2-1.651780128479004\n",
      "outer_epoch&task148  eval_loss:0.001816136878915131 r2-0.2979419231414795\n",
      "outer_epoch&task149  eval_loss:0.003646315773949027 r2-1.295961856842041\n",
      "0.014678486\n",
      "-------------------------MSE_LR_OUTER1e-06--EPOCH_INNER3--------------------------\n",
      "outer_epoch&task0  eval_loss:0.00244199694134295 r2-0.5720260143280029\n",
      "outer_epoch&task1  eval_loss:0.0019878835882991552 r2-0.2648580074310303\n",
      "outer_epoch&task2  eval_loss:0.001325565273873508 r2-0.24699032306671143\n",
      "outer_epoch&task3  eval_loss:0.0023891408927738667 r2-0.43063580989837646\n",
      "outer_epoch&task4  eval_loss:0.0021726477425545454 r2-0.7634639739990234\n",
      "outer_epoch&task5  eval_loss:0.00151273503433913 r2-0.08209192752838135\n",
      "outer_epoch&task6  eval_loss:0.002277929335832596 r2-0.7004822492599487\n",
      "outer_epoch&task7  eval_loss:0.002103062579408288 r2-0.9268110990524292\n",
      "outer_epoch&task8  eval_loss:0.0024790235329419374 r2-0.5569460391998291\n",
      "outer_epoch&task9  eval_loss:0.0015758180525153875 r2-0.1977372169494629\n",
      "outer_epoch&task10  eval_loss:0.0014542973367497325 r2-0.09180986881256104\n",
      "outer_epoch&task11  eval_loss:0.0019137602066621184 r2-0.5811811685562134\n",
      "outer_epoch&task12  eval_loss:0.00266643101349473 r2-0.7784411907196045\n",
      "outer_epoch&task13  eval_loss:0.0021837870590388775 r2-0.632530689239502\n",
      "outer_epoch&task14  eval_loss:0.002438705414533615 r2-0.7419770956039429\n",
      "outer_epoch&task15  eval_loss:0.002555446932092309 r2-0.8445162773132324\n",
      "outer_epoch&task16  eval_loss:0.0025053590070456266 r2-0.6380437612533569\n",
      "outer_epoch&task17  eval_loss:0.0027047006879001856 r2-0.6691383123397827\n",
      "outer_epoch&task18  eval_loss:0.002264412585645914 r2-0.49674081802368164\n",
      "outer_epoch&task19  eval_loss:0.0022986368276178837 r2-0.7095339298248291\n",
      "outer_epoch&task20  eval_loss:0.002823158632963896 r2-1.0335087776184082\n",
      "outer_epoch&task21  eval_loss:0.0015308513538911939 r2-0.1854332685470581\n",
      "outer_epoch&task22  eval_loss:0.0023463440593332052 r2-0.6417138576507568\n",
      "outer_epoch&task23  eval_loss:0.0029585810843855143 r2-0.7117329835891724\n",
      "outer_epoch&task24  eval_loss:0.002302139066159725 r2-0.7412090301513672\n",
      "outer_epoch&task25  eval_loss:0.0025611338205635548 r2-0.6792892217636108\n",
      "outer_epoch&task26  eval_loss:0.0025653867051005363 r2-0.853904128074646\n",
      "outer_epoch&task27  eval_loss:0.003979640547186136 r2-2.2653844356536865\n",
      "outer_epoch&task28  eval_loss:0.002539826789870858 r2-0.6446816921234131\n",
      "outer_epoch&task29  eval_loss:0.0030023923609405756 r2-1.0789728164672852\n",
      "outer_epoch&task30  eval_loss:0.0025336123071610928 r2-0.7673099040985107\n",
      "outer_epoch&task31  eval_loss:0.003563973121345043 r2-1.8950231075286865\n",
      "outer_epoch&task32  eval_loss:0.0049366396851837635 r2-1.9630062580108643\n",
      "outer_epoch&task33  eval_loss:0.004120644647628069 r2-2.136335849761963\n",
      "outer_epoch&task34  eval_loss:0.004088434856384993 r2-1.9628665447235107\n",
      "outer_epoch&task35  eval_loss:0.004221589304506779 r2-2.036055564880371\n",
      "outer_epoch&task36  eval_loss:0.0038908179849386215 r2-1.6067328453063965\n",
      "outer_epoch&task37  eval_loss:0.003891021478921175 r2-1.4619154930114746\n",
      "outer_epoch&task38  eval_loss:0.004933024290949106 r2-2.8070108890533447\n",
      "outer_epoch&task39  eval_loss:0.004719301126897335 r2-2.2294564247131348\n",
      "outer_epoch&task40  eval_loss:0.004431048408150673 r2-2.3565597534179688\n",
      "outer_epoch&task41  eval_loss:0.0026012244634330273 r2-1.2507526874542236\n",
      "outer_epoch&task42  eval_loss:0.005034246947616339 r2-2.7848029136657715\n",
      "outer_epoch&task43  eval_loss:0.004194116685539484 r2-2.883060932159424\n",
      "outer_epoch&task44  eval_loss:0.004743392113596201 r2-2.454068183898926\n",
      "outer_epoch&task45  eval_loss:0.0045379893854260445 r2-1.98329758644104\n",
      "outer_epoch&task46  eval_loss:0.004857584834098816 r2-2.2534451484680176\n",
      "outer_epoch&task47  eval_loss:0.004342739470303059 r2-2.134737253189087\n",
      "outer_epoch&task48  eval_loss:0.005051462911069393 r2-3.103856086730957\n",
      "outer_epoch&task49  eval_loss:0.004942269530147314 r2-3.085360050201416\n",
      "outer_epoch&task50  eval_loss:0.006579035893082619 r2-4.10267448425293\n",
      "outer_epoch&task51  eval_loss:0.005999819841235876 r2-3.493771553039551\n",
      "outer_epoch&task52  eval_loss:0.005936906673014164 r2-2.9638783931732178\n",
      "outer_epoch&task53  eval_loss:0.005100401584059 r2-2.434014320373535\n",
      "outer_epoch&task54  eval_loss:0.004457803443074226 r2-2.193899631500244\n",
      "outer_epoch&task55  eval_loss:0.004248791839927435 r2-2.405142068862915\n",
      "outer_epoch&task56  eval_loss:0.0064890277571976185 r2-3.4734792709350586\n",
      "outer_epoch&task57  eval_loss:0.004323273431509733 r2-2.3016912937164307\n",
      "outer_epoch&task58  eval_loss:0.00635521300137043 r2-2.9254603385925293\n",
      "outer_epoch&task59  eval_loss:0.005304719787091017 r2-2.1638238430023193\n",
      "outer_epoch&task60  eval_loss:0.006158503238111734 r2-3.2698311805725098\n",
      "outer_epoch&task61  eval_loss:0.006187345366925001 r2-3.561581611633301\n",
      "outer_epoch&task62  eval_loss:0.00816033873707056 r2-6.15422248840332\n",
      "outer_epoch&task63  eval_loss:0.004751917440444231 r2-2.4761977195739746\n",
      "outer_epoch&task64  eval_loss:0.0048059807159006596 r2-2.023033857345581\n",
      "outer_epoch&task65  eval_loss:0.005119671113789082 r2-2.2682039737701416\n",
      "outer_epoch&task66  eval_loss:0.005977066233754158 r2-3.08229923248291\n",
      "outer_epoch&task67  eval_loss:0.0047677247785031796 r2-2.2710320949554443\n",
      "outer_epoch&task68  eval_loss:0.0048932177014648914 r2-2.19437313079834\n",
      "outer_epoch&task69  eval_loss:0.004207767080515623 r2-2.2484660148620605\n",
      "outer_epoch&task70  eval_loss:0.005038233939558268 r2-2.8571271896362305\n",
      "outer_epoch&task71  eval_loss:0.004407417960464954 r2-1.651871681213379\n",
      "outer_epoch&task72  eval_loss:0.004828799515962601 r2-1.9250481128692627\n",
      "outer_epoch&task73  eval_loss:0.008591338992118835 r2-5.469418525695801\n",
      "outer_epoch&task74  eval_loss:0.006581158842891455 r2-3.974923610687256\n",
      "outer_epoch&task75  eval_loss:0.0043584974482655525 r2-2.4482483863830566\n",
      "outer_epoch&task76  eval_loss:0.006460619159042835 r2-3.3880844116210938\n",
      "outer_epoch&task77  eval_loss:0.009112243540585041 r2-5.386905193328857\n",
      "outer_epoch&task78  eval_loss:0.006544748321175575 r2-3.7904629707336426\n",
      "outer_epoch&task79  eval_loss:0.004585891496390104 r2-2.863959550857544\n",
      "outer_epoch&task80  eval_loss:0.004230642691254616 r2-2.1137540340423584\n",
      "outer_epoch&task81  eval_loss:0.004023293033242226 r2-2.476163864135742\n",
      "outer_epoch&task82  eval_loss:0.005005913786590099 r2-3.392822742462158\n",
      "outer_epoch&task83  eval_loss:0.005530938971787691 r2-2.0388057231903076\n",
      "outer_epoch&task84  eval_loss:0.005329441279172897 r2-2.6355011463165283\n",
      "outer_epoch&task85  eval_loss:0.005161687731742859 r2-2.540964126586914\n",
      "outer_epoch&task86  eval_loss:0.005207053851336241 r2-2.3276891708374023\n",
      "outer_epoch&task87  eval_loss:0.008528579957783222 r2-3.9684839248657227\n",
      "outer_epoch&task88  eval_loss:0.008181996643543243 r2-3.943741798400879\n",
      "outer_epoch&task89  eval_loss:0.012064851820468903 r2-6.729567527770996\n",
      "outer_epoch&task90  eval_loss:0.005923501681536436 r2-3.404045581817627\n",
      "outer_epoch&task91  eval_loss:0.005792863667011261 r2-3.2357354164123535\n",
      "outer_epoch&task92  eval_loss:0.003961511421948671 r2-1.9704012870788574\n",
      "outer_epoch&task93  eval_loss:0.0116411242634058 r2-7.4995832443237305\n",
      "outer_epoch&task94  eval_loss:0.0057008108124136925 r2-2.634012460708618\n",
      "outer_epoch&task95  eval_loss:0.004547901451587677 r2-2.4177019596099854\n",
      "outer_epoch&task96  eval_loss:0.0051919748075306416 r2-2.626542091369629\n",
      "outer_epoch&task97  eval_loss:0.004972005728632212 r2-2.2253975868225098\n",
      "outer_epoch&task98  eval_loss:0.004547408316284418 r2-2.09189772605896\n",
      "outer_epoch&task99  eval_loss:0.004537192173302174 r2-2.615987539291382\n",
      "outer_epoch&task100  eval_loss:0.0043136184103786945 r2-2.2910306453704834\n",
      "outer_epoch&task101  eval_loss:0.004982818849384785 r2-2.6196765899658203\n",
      "outer_epoch&task102  eval_loss:0.005556707736104727 r2-3.0651416778564453\n",
      "outer_epoch&task103  eval_loss:0.00970384944230318 r2-4.8973588943481445\n",
      "outer_epoch&task104  eval_loss:0.005825974978506565 r2-2.4799599647521973\n",
      "outer_epoch&task105  eval_loss:0.00489716324955225 r2-1.8579118251800537\n",
      "outer_epoch&task106  eval_loss:0.004483417607843876 r2-2.7651267051696777\n",
      "outer_epoch&task107  eval_loss:0.0043801418505609035 r2-2.352278709411621\n",
      "outer_epoch&task108  eval_loss:0.004221924114972353 r2-2.1200883388519287\n",
      "outer_epoch&task109  eval_loss:0.004950338508933783 r2-2.243279457092285\n",
      "outer_epoch&task110  eval_loss:0.008978202007710934 r2-5.822864532470703\n",
      "outer_epoch&task111  eval_loss:0.009411878883838654 r2-5.827302932739258\n",
      "outer_epoch&task112  eval_loss:0.005332666449248791 r2-2.623006820678711\n",
      "outer_epoch&task113  eval_loss:0.005784870125353336 r2-3.359344005584717\n",
      "outer_epoch&task114  eval_loss:0.0031441363971680403 r2-1.3707029819488525\n",
      "outer_epoch&task115  eval_loss:0.0077683404088020325 r2-4.211038589477539\n",
      "outer_epoch&task116  eval_loss:0.004398648161441088 r2-2.545909881591797\n",
      "outer_epoch&task117  eval_loss:0.005111038219183683 r2-1.771240472793579\n",
      "outer_epoch&task118  eval_loss:0.008930215612053871 r2-5.851022243499756\n",
      "outer_epoch&task119  eval_loss:0.005454214755445719 r2-2.9603686332702637\n",
      "outer_epoch&task120  eval_loss:0.006950660143047571 r2-3.4705681800842285\n",
      "outer_epoch&task121  eval_loss:0.004744715057313442 r2-2.892728567123413\n",
      "outer_epoch&task122  eval_loss:0.005565668921917677 r2-2.811978816986084\n",
      "outer_epoch&task123  eval_loss:0.005605707410722971 r2-3.1705331802368164\n",
      "outer_epoch&task124  eval_loss:0.004819846246391535 r2-2.858055591583252\n",
      "outer_epoch&task125  eval_loss:0.0033524720929563046 r2-1.1499195098876953\n",
      "outer_epoch&task126  eval_loss:0.00780852884054184 r2-4.2504448890686035\n",
      "outer_epoch&task127  eval_loss:0.007018926087766886 r2-5.94905948638916\n",
      "outer_epoch&task128  eval_loss:0.006231051869690418 r2-2.9068033695220947\n",
      "outer_epoch&task129  eval_loss:0.004756100941449404 r2-2.389752149581909\n",
      "outer_epoch&task130  eval_loss:0.004096406977623701 r2-2.2002112865448\n",
      "outer_epoch&task131  eval_loss:0.003770997282117605 r2-1.1735687255859375\n",
      "outer_epoch&task132  eval_loss:0.002686375519260764 r2-0.9076554775238037\n",
      "outer_epoch&task133  eval_loss:0.007815192453563213 r2-4.54351282119751\n",
      "outer_epoch&task134  eval_loss:0.007640794385224581 r2-5.071771621704102\n",
      "outer_epoch&task135  eval_loss:0.0034358741249889135 r2-1.275467872619629\n",
      "outer_epoch&task136  eval_loss:0.006051357835531235 r2-3.9599757194519043\n",
      "outer_epoch&task137  eval_loss:0.0026680375449359417 r2-0.7418217658996582\n",
      "outer_epoch&task138  eval_loss:0.0036728184204548597 r2-1.5056705474853516\n",
      "outer_epoch&task139  eval_loss:0.006113484036177397 r2-4.29288387298584\n",
      "outer_epoch&task140  eval_loss:0.004730519372969866 r2-2.367647886276245\n",
      "outer_epoch&task141  eval_loss:0.002620546380057931 r2-1.0002107620239258\n",
      "outer_epoch&task142  eval_loss:0.005989897530525923 r2-3.7574024200439453\n",
      "outer_epoch&task143  eval_loss:0.0035737373400479555 r2-1.3703651428222656\n",
      "outer_epoch&task144  eval_loss:0.004061876330524683 r2-1.829615592956543\n",
      "outer_epoch&task145  eval_loss:0.0037341956049203873 r2-1.3766660690307617\n",
      "outer_epoch&task146  eval_loss:0.005068922881036997 r2-2.8499457836151123\n",
      "outer_epoch&task147  eval_loss:0.00872412696480751 r2-5.664778709411621\n",
      "outer_epoch&task148  eval_loss:0.006412618327885866 r2-5.06034517288208\n",
      "outer_epoch&task149  eval_loss:0.0037569329142570496 r2-1.527890920639038\n",
      "0.019483136\n"
     ]
    }
   ],
   "source": [
    "from reptile_train import *\n",
    "from para import*\n",
    "from normal_train import*\n",
    "\n",
    "####\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)\n",
    "####\n",
    "LR_OUTER=1e-06\n",
    "EPOCH_INNER=3\n",
    "\n",
    "model_path_reptile =f\"./saved_model/new_reptile_MSE_lro{LR_OUTER}_ei{EPOCH_INNER}.pth\"\n",
    "testset=MateCo2Dataset(\"./data_meta\", 12)\n",
    "model = build_resunetplusplus()\n",
    "model = model.to(DEVICE)\n",
    "train_loader = DataLoader(testset, batch_size=1, shuffle=True)\n",
    "targetset=MateCo2Dataset(\"./target_task/data_meta\", 48)\n",
    "eval_loader = DataLoader(targetset, batch_size=1, shuffle=False)\n",
    "loss_reptile=outter_loop(model, train_loader, EPOCH_OUTTER, EPOCH_INNER, eval_loader, LR_OUTER, BZ_OUTTER, LR_INNER, BZ_INNER,device=DEVICE, save_path=model_path_reptile)\n",
    "print(np.mean(loss_reptile))\n",
    "np.savetxt(f\"new_reptile_MSEloss_lro{LR_OUTER}_ei{EPOCH_INNER}.csv\", loss_reptile, delimiter=\",\")\n",
    "selected_epoch=list(np.linspace(9,50-1,8,dtype=np.int16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_epoch=list(np.linspace(0,epochs_outer-1,5,dtype=np.int16))\n",
    "plot(loss_reptile, selected_epoch, 'reptile_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)\n",
    "\n",
    "model_path_reptile = \"./saved_model/reptile_MSE_lro1e-06_ei3.pth\"\n",
    "ns_ls=[16,32,63]\n",
    "dataset=NomalCo2Dataset_loadALL(\"./target_task/data_normal\")\n",
    "\n",
    "for ns in ns_ls:\n",
    "    ns_=63-ns\n",
    "    print(f\"--------------------------NS{ns}lro0.0001_ei3_____________________________\")\n",
    "    dataset_i, _= torch.utils.data.random_split(dataset, [ns, ns_])\n",
    "    \n",
    "    model = build_resunetplusplus()\n",
    "    checkpoint = torch.load(model_path_reptile)\n",
    "    model.load_state_dict(checkpoint)   \n",
    "    model = model.to(DEVICE)\n",
    "    loss_finetune_reptile,mea_finetune_reptile,r2_finetune_reptile,ssim_finetune_reptile=normal_train(model, dataset_i, 0.25, EPOCH, BATCH_SIZE, LR, DEVICE, None)\n",
    "    \n",
    "    print(f\"-----------------------------------------normalloss_mse_lr{LR}_ns{ns}---------------------------------------------\")\n",
    "    model = build_resunetplusplus()\n",
    "    model = model.to(DEVICE)\n",
    "    loss_normal,mea_normal,r2_normal,ssim_normal=normal_train(model, dataset_i, 0.25, EPOCH, BATCH_SIZE, LR, DEVICE,None)\n",
    "\n",
    "    plot_compare(loss_finetune_reptile, loss_normal, name=f'compare_mse_ns{ns}')\n",
    "    plot_compare(mea_finetune_reptile, mea_normal, name=f'compare_mea_ns{ns}')\n",
    "    plot_compare(r2_finetune_reptile, r2_normal, name=f'compare_r2_ns{ns}')\n",
    "    plot_compare(ssim_finetune_reptile, ssim_normal, name=f'compare_ssim_ns{ns}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "{'sample': 33, 'model_name': './model/normal_fineds_mse_lr0.001_ns16.pth', 'num_sample': 16, 'ssim': 0.8895488977432251, 'mse': array(0.00069924, dtype=float32), 'mea': array(0.00809634, dtype=float32), 'r^2': array(0.45159423, dtype=float32)}\n",
      "{'sample': 33, 'model_name': './model/finetune_reptilee_MSE_lro0.0001_lri0.001_ns16.pth', 'num_sample': 16, 'ssim': 0.9279865622520447, 'mse': array(0.00023026, dtype=float32), 'mea': array(0.00475256, dtype=float32), 'r^2': array(0.8194066, dtype=float32)}\n",
      "{'sample': 34, 'model_name': './model/normal_fineds_mse_lr0.001_ns16.pth', 'num_sample': 16, 'ssim': 0.9153656363487244, 'mse': array(0.00079507, dtype=float32), 'mea': array(0.00642757, dtype=float32), 'r^2': array(0.25322002, dtype=float32)}\n",
      "{'sample': 34, 'model_name': './model/finetune_reptilee_MSE_lro0.0001_lri0.001_ns16.pth', 'num_sample': 16, 'ssim': 0.9286301732063293, 'mse': array(0.00015989, dtype=float32), 'mea': array(0.0042246, dtype=float32), 'r^2': array(0.84981865, dtype=float32)}\n",
      "{'sample': 36, 'model_name': './model/normal_fineds_mse_lr0.001_ns16.pth', 'num_sample': 16, 'ssim': 0.8903730511665344, 'mse': array(0.00069179, dtype=float32), 'mea': array(0.00764387, dtype=float32), 'r^2': array(0.6376505, dtype=float32)}\n",
      "{'sample': 36, 'model_name': './model/finetune_reptilee_MSE_lro0.0001_lri0.001_ns16.pth', 'num_sample': 16, 'ssim': 0.9064926505088806, 'mse': array(0.00020712, dtype=float32), 'mea': array(0.00532687, dtype=float32), 'r^2': array(0.89151675, dtype=float32)}\n",
      "{'sample': 37, 'model_name': './model/normal_fineds_mse_lr0.001_ns16.pth', 'num_sample': 16, 'ssim': 0.889279842376709, 'mse': array(0.00040219, dtype=float32), 'mea': array(0.00699996, dtype=float32), 'r^2': array(0.79553187, dtype=float32)}\n",
      "{'sample': 37, 'model_name': './model/finetune_reptilee_MSE_lro0.0001_lri0.001_ns16.pth', 'num_sample': 16, 'ssim': 0.903729259967804, 'mse': array(0.00028966, dtype=float32), 'mea': array(0.00605655, dtype=float32), 'r^2': array(0.8527388, dtype=float32)}\n",
      "{'sample': 38, 'model_name': './model/normal_fineds_mse_lr0.001_ns16.pth', 'num_sample': 16, 'ssim': 0.9102464914321899, 'mse': array(0.00024712, dtype=float32), 'mea': array(0.00554163, dtype=float32), 'r^2': array(0.86983585, dtype=float32)}\n",
      "{'sample': 38, 'model_name': './model/finetune_reptilee_MSE_lro0.0001_lri0.001_ns16.pth', 'num_sample': 16, 'ssim': 0.9261309504508972, 'mse': array(0.00021625, dtype=float32), 'mea': array(0.00498589, dtype=float32), 'r^2': array(0.8860939, dtype=float32)}\n",
      "{'sample': 51, 'model_name': './model/normal_fineds_mse_lr0.001_ns16.pth', 'num_sample': 16, 'ssim': 0.9061259627342224, 'mse': array(0.00045124, dtype=float32), 'mea': array(0.00584998, dtype=float32), 'r^2': array(0.22178221, dtype=float32)}\n",
      "{'sample': 51, 'model_name': './model/finetune_reptilee_MSE_lro0.0001_lri0.001_ns16.pth', 'num_sample': 16, 'ssim': 0.9056307077407837, 'mse': array(0.00028131, dtype=float32), 'mea': array(0.00501594, dtype=float32), 'r^2': array(0.5148412, dtype=float32)}\n",
      "{'sample': 52, 'model_name': './model/normal_fineds_mse_lr0.001_ns16.pth', 'num_sample': 16, 'ssim': 0.8939351439476013, 'mse': array(0.00039568, dtype=float32), 'mea': array(0.00659404, dtype=float32), 'r^2': array(0.80855185, dtype=float32)}\n",
      "{'sample': 52, 'model_name': './model/finetune_reptilee_MSE_lro0.0001_lri0.001_ns16.pth', 'num_sample': 16, 'ssim': 0.8873526453971863, 'mse': array(0.00023451, dtype=float32), 'mea': array(0.00577059, dtype=float32), 'r^2': array(0.8865327, dtype=float32)}\n",
      "{'sample': 53, 'model_name': './model/normal_fineds_mse_lr0.001_ns16.pth', 'num_sample': 16, 'ssim': 0.8952046632766724, 'mse': array(0.00059582, dtype=float32), 'mea': array(0.00758253, dtype=float32), 'r^2': array(0.6201925, dtype=float32)}\n",
      "{'sample': 53, 'model_name': './model/finetune_reptilee_MSE_lro0.0001_lri0.001_ns16.pth', 'num_sample': 16, 'ssim': 0.9338322877883911, 'mse': array(0.00021469, dtype=float32), 'mea': array(0.00473096, dtype=float32), 'r^2': array(0.86314696, dtype=float32)}\n",
      "{'sample': 58, 'model_name': './model/normal_fineds_mse_lr0.001_ns16.pth', 'num_sample': 16, 'ssim': 0.8844451308250427, 'mse': array(0.00128312, dtype=float32), 'mea': array(0.00869652, dtype=float32), 'r^2': array(0.23820084, dtype=float32)}\n",
      "{'sample': 58, 'model_name': './model/finetune_reptilee_MSE_lro0.0001_lri0.001_ns16.pth', 'num_sample': 16, 'ssim': 0.9137916564941406, 'mse': array(0.00022466, dtype=float32), 'mea': array(0.00512664, dtype=float32), 'r^2': array(0.8666203, dtype=float32)}\n",
      "{'sample': 59, 'model_name': './model/normal_fineds_mse_lr0.001_ns16.pth', 'num_sample': 16, 'ssim': 0.9190673232078552, 'mse': array(0.00031562, dtype=float32), 'mea': array(0.00544176, dtype=float32), 'r^2': array(0.81193066, dtype=float32)}\n",
      "{'sample': 59, 'model_name': './model/finetune_reptilee_MSE_lro0.0001_lri0.001_ns16.pth', 'num_sample': 16, 'ssim': 0.9166306853294373, 'mse': array(0.000366, dtype=float32), 'mea': array(0.0059264, dtype=float32), 'r^2': array(0.7819099, dtype=float32)}\n",
      "{'sample': 61, 'model_name': './model/normal_fineds_mse_lr0.001_ns16.pth', 'num_sample': 16, 'ssim': 0.8895512819290161, 'mse': array(0.00100004, dtype=float32), 'mea': array(0.00863688, dtype=float32), 'r^2': array(-0.30110168, dtype=float32)}\n",
      "{'sample': 61, 'model_name': './model/finetune_reptilee_MSE_lro0.0001_lri0.001_ns16.pth', 'num_sample': 16, 'ssim': 0.9369349479675293, 'mse': array(0.0001781, dtype=float32), 'mea': array(0.00395134, dtype=float32), 'r^2': array(0.7682779, dtype=float32)}\n",
      "{'sample': 62, 'model_name': './model/normal_fineds_mse_lr0.001_ns16.pth', 'num_sample': 16, 'ssim': 0.9037953615188599, 'mse': array(0.0004052, dtype=float32), 'mea': array(0.00647797, dtype=float32), 'r^2': array(0.75895756, dtype=float32)}\n",
      "{'sample': 62, 'model_name': './model/finetune_reptilee_MSE_lro0.0001_lri0.001_ns16.pth', 'num_sample': 16, 'ssim': 0.894158661365509, 'mse': array(0.00038989, dtype=float32), 'mea': array(0.00661841, dtype=float32), 'r^2': array(0.7680681, dtype=float32)}\n",
      "{'sample': 33, 'model_name': './model/normal_fineds_mse_lr0.001_ns32.pth', 'num_sample': 32, 'ssim': 0.8798578381538391, 'mse': array(0.00032831, dtype=float32), 'mea': array(0.00687251, dtype=float32), 'r^2': array(0.7425114, dtype=float32)}\n",
      "{'sample': 33, 'model_name': './model/finetune_reptilee_MSE_lro0.0001_lri0.001_ns32.pth', 'num_sample': 32, 'ssim': 0.9462122321128845, 'mse': array(0.0001541, dtype=float32), 'mea': array(0.00407645, dtype=float32), 'r^2': array(0.87913907, dtype=float32)}\n",
      "{'sample': 34, 'model_name': './model/normal_fineds_mse_lr0.001_ns32.pth', 'num_sample': 32, 'ssim': 0.8896183967590332, 'mse': array(0.0001426, dtype=float32), 'mea': array(0.00539085, dtype=float32), 'r^2': array(0.8660568, dtype=float32)}\n",
      "{'sample': 34, 'model_name': './model/finetune_reptilee_MSE_lro0.0001_lri0.001_ns32.pth', 'num_sample': 32, 'ssim': 0.9575309157371521, 'mse': array(0.00011218, dtype=float32), 'mea': array(0.00342173, dtype=float32), 'r^2': array(0.89463115, dtype=float32)}\n",
      "{'sample': 36, 'model_name': './model/normal_fineds_mse_lr0.001_ns32.pth', 'num_sample': 32, 'ssim': 0.8742873072624207, 'mse': array(0.00019125, dtype=float32), 'mea': array(0.00649798, dtype=float32), 'r^2': array(0.8998273, dtype=float32)}\n",
      "{'sample': 36, 'model_name': './model/finetune_reptilee_MSE_lro0.0001_lri0.001_ns32.pth', 'num_sample': 32, 'ssim': 0.9377625584602356, 'mse': array(0.0001446, dtype=float32), 'mea': array(0.00417597, dtype=float32), 'r^2': array(0.9242626, dtype=float32)}\n",
      "{'sample': 37, 'model_name': './model/normal_fineds_mse_lr0.001_ns32.pth', 'num_sample': 32, 'ssim': 0.8152294158935547, 'mse': array(0.00075593, dtype=float32), 'mea': array(0.01002199, dtype=float32), 'r^2': array(0.61569417, dtype=float32)}\n",
      "{'sample': 37, 'model_name': './model/finetune_reptilee_MSE_lro0.0001_lri0.001_ns32.pth', 'num_sample': 32, 'ssim': 0.9352216124534607, 'mse': array(0.00012931, dtype=float32), 'mea': array(0.00417641, dtype=float32), 'r^2': array(0.93426216, dtype=float32)}\n",
      "{'sample': 38, 'model_name': './model/normal_fineds_mse_lr0.001_ns32.pth', 'num_sample': 32, 'ssim': 0.850685715675354, 'mse': array(0.00062281, dtype=float32), 'mea': array(0.00853131, dtype=float32), 'r^2': array(0.6719459, dtype=float32)}\n",
      "{'sample': 38, 'model_name': './model/finetune_reptilee_MSE_lro0.0001_lri0.001_ns32.pth', 'num_sample': 32, 'ssim': 0.9455036520957947, 'mse': array(0.00014214, dtype=float32), 'mea': array(0.00403178, dtype=float32), 'r^2': array(0.92513293, dtype=float32)}\n",
      "{'sample': 51, 'model_name': './model/normal_fineds_mse_lr0.001_ns32.pth', 'num_sample': 32, 'ssim': 0.8669248819351196, 'mse': array(0.00025795, dtype=float32), 'mea': array(0.00627326, dtype=float32), 'r^2': array(0.5551336, dtype=float32)}\n",
      "{'sample': 51, 'model_name': './model/finetune_reptilee_MSE_lro0.0001_lri0.001_ns32.pth', 'num_sample': 32, 'ssim': 0.9008755683898926, 'mse': array(0.00028812, dtype=float32), 'mea': array(0.00545417, dtype=float32), 'r^2': array(0.50309396, dtype=float32)}\n",
      "{'sample': 52, 'model_name': './model/normal_fineds_mse_lr0.001_ns32.pth', 'num_sample': 32, 'ssim': 0.8570930361747742, 'mse': array(0.00025437, dtype=float32), 'mea': array(0.00729845, dtype=float32), 'r^2': array(0.8769226, dtype=float32)}\n",
      "{'sample': 52, 'model_name': './model/finetune_reptilee_MSE_lro0.0001_lri0.001_ns32.pth', 'num_sample': 32, 'ssim': 0.9364036917686462, 'mse': array(0.00012057, dtype=float32), 'mea': array(0.00404159, dtype=float32), 'r^2': array(0.94166046, dtype=float32)}\n",
      "{'sample': 53, 'model_name': './model/normal_fineds_mse_lr0.001_ns32.pth', 'num_sample': 32, 'ssim': 0.8699589967727661, 'mse': array(0.00033073, dtype=float32), 'mea': array(0.00720601, dtype=float32), 'r^2': array(0.7891775, dtype=float32)}\n",
      "{'sample': 53, 'model_name': './model/finetune_reptilee_MSE_lro0.0001_lri0.001_ns32.pth', 'num_sample': 32, 'ssim': 0.9517016410827637, 'mse': array(0.00012276, dtype=float32), 'mea': array(0.00371661, dtype=float32), 'r^2': array(0.92174596, dtype=float32)}\n",
      "{'sample': 58, 'model_name': './model/normal_fineds_mse_lr0.001_ns32.pth', 'num_sample': 32, 'ssim': 0.8764095306396484, 'mse': array(0.00021246, dtype=float32), 'mea': array(0.00642319, dtype=float32), 'r^2': array(0.8738592, dtype=float32)}\n",
      "{'sample': 58, 'model_name': './model/finetune_reptilee_MSE_lro0.0001_lri0.001_ns32.pth', 'num_sample': 32, 'ssim': 0.9591715931892395, 'mse': array(8.2790284e-05, dtype=float32), 'mea': array(0.00314867, dtype=float32), 'r^2': array(0.9508468, dtype=float32)}\n",
      "{'sample': 59, 'model_name': './model/normal_fineds_mse_lr0.001_ns32.pth', 'num_sample': 32, 'ssim': 0.867982029914856, 'mse': array(0.00032119, dtype=float32), 'mea': array(0.0071887, dtype=float32), 'r^2': array(0.8086101, dtype=float32)}\n",
      "{'sample': 59, 'model_name': './model/finetune_reptilee_MSE_lro0.0001_lri0.001_ns32.pth', 'num_sample': 32, 'ssim': 0.9289337992668152, 'mse': array(0.00027779, dtype=float32), 'mea': array(0.00512643, dtype=float32), 'r^2': array(0.8344704, dtype=float32)}\n",
      "{'sample': 61, 'model_name': './model/normal_fineds_mse_lr0.001_ns32.pth', 'num_sample': 32, 'ssim': 0.896867573261261, 'mse': array(0.00031977, dtype=float32), 'mea': array(0.00631044, dtype=float32), 'r^2': array(0.5839603, dtype=float32)}\n",
      "{'sample': 61, 'model_name': './model/finetune_reptilee_MSE_lro0.0001_lri0.001_ns32.pth', 'num_sample': 32, 'ssim': 0.882814884185791, 'mse': array(0.00044611, dtype=float32), 'mea': array(0.00674403, dtype=float32), 'r^2': array(0.41959018, dtype=float32)}\n",
      "{'sample': 62, 'model_name': './model/normal_fineds_mse_lr0.001_ns32.pth', 'num_sample': 32, 'ssim': 0.8623278737068176, 'mse': array(0.0003131, dtype=float32), 'mea': array(0.00742331, dtype=float32), 'r^2': array(0.8137443, dtype=float32)}\n",
      "{'sample': 62, 'model_name': './model/finetune_reptilee_MSE_lro0.0001_lri0.001_ns32.pth', 'num_sample': 32, 'ssim': 0.9447270631790161, 'mse': array(0.00017253, dtype=float32), 'mea': array(0.0042264, dtype=float32), 'r^2': array(0.8973702, dtype=float32)}\n",
      "{'sample': 33, 'model_name': './model/normal_fineds_mse_lr0.001_ns63.pth', 'num_sample': 63, 'ssim': 0.9321731925010681, 'mse': array(0.00013384, dtype=float32), 'mea': array(0.00412118, dtype=float32), 'r^2': array(0.89503336, dtype=float32)}\n",
      "{'sample': 33, 'model_name': './model/finetune_reptilee_MSE_lro0.0001_lri0.001_ns63.pth', 'num_sample': 63, 'ssim': 0.9452609419822693, 'mse': array(0.00014056, dtype=float32), 'mea': array(0.00384971, dtype=float32), 'r^2': array(0.88976425, dtype=float32)}\n",
      "{'sample': 34, 'model_name': './model/normal_fineds_mse_lr0.001_ns63.pth', 'num_sample': 63, 'ssim': 0.9065336585044861, 'mse': array(6.054938e-05, dtype=float32), 'mea': array(0.00424838, dtype=float32), 'r^2': array(0.9431279, dtype=float32)}\n",
      "{'sample': 34, 'model_name': './model/finetune_reptilee_MSE_lro0.0001_lri0.001_ns63.pth', 'num_sample': 63, 'ssim': 0.9544154405593872, 'mse': array(5.844013e-05, dtype=float32), 'mea': array(0.00293204, dtype=float32), 'r^2': array(0.945109, dtype=float32)}\n",
      "{'sample': 36, 'model_name': './model/normal_fineds_mse_lr0.001_ns63.pth', 'num_sample': 63, 'ssim': 0.9041867256164551, 'mse': array(7.204769e-05, dtype=float32), 'mea': array(0.00474387, dtype=float32), 'r^2': array(0.96226275, dtype=float32)}\n",
      "{'sample': 36, 'model_name': './model/finetune_reptilee_MSE_lro0.0001_lri0.001_ns63.pth', 'num_sample': 63, 'ssim': 0.938034176826477, 'mse': array(8.884088e-05, dtype=float32), 'mea': array(0.00395968, dtype=float32), 'r^2': array(0.9534668, dtype=float32)}\n",
      "{'sample': 37, 'model_name': './model/normal_fineds_mse_lr0.001_ns63.pth', 'num_sample': 63, 'ssim': 0.8877641558647156, 'mse': array(0.00013005, dtype=float32), 'mea': array(0.00562953, dtype=float32), 'r^2': array(0.9338854, dtype=float32)}\n",
      "{'sample': 37, 'model_name': './model/finetune_reptilee_MSE_lro0.0001_lri0.001_ns63.pth', 'num_sample': 63, 'ssim': 0.8897188305854797, 'mse': array(0.00036935, dtype=float32), 'mea': array(0.00653517, dtype=float32), 'r^2': array(0.81222713, dtype=float32)}\n",
      "{'sample': 38, 'model_name': './model/normal_fineds_mse_lr0.001_ns63.pth', 'num_sample': 63, 'ssim': 0.887443482875824, 'mse': array(0.00010698, dtype=float32), 'mea': array(0.00525475, dtype=float32), 'r^2': array(0.94365144, dtype=float32)}\n",
      "{'sample': 38, 'model_name': './model/finetune_reptilee_MSE_lro0.0001_lri0.001_ns63.pth', 'num_sample': 63, 'ssim': 0.9231967926025391, 'mse': array(0.00011806, dtype=float32), 'mea': array(0.00432534, dtype=float32), 'r^2': array(0.9378166, dtype=float32)}\n",
      "{'sample': 51, 'model_name': './model/normal_fineds_mse_lr0.001_ns63.pth', 'num_sample': 63, 'ssim': 0.9084370732307434, 'mse': array(0.00010878, dtype=float32), 'mea': array(0.00436218, dtype=float32), 'r^2': array(0.8123999, dtype=float32)}\n",
      "{'sample': 51, 'model_name': './model/finetune_reptilee_MSE_lro0.0001_lri0.001_ns63.pth', 'num_sample': 63, 'ssim': 0.9508559107780457, 'mse': array(5.325799e-05, dtype=float32), 'mea': array(0.00278345, dtype=float32), 'r^2': array(0.90815, dtype=float32)}\n",
      "{'sample': 52, 'model_name': './model/normal_fineds_mse_lr0.001_ns63.pth', 'num_sample': 63, 'ssim': 0.8687146306037903, 'mse': array(0.00020241, dtype=float32), 'mea': array(0.00630395, dtype=float32), 'r^2': array(0.9020637, dtype=float32)}\n",
      "{'sample': 52, 'model_name': './model/finetune_reptilee_MSE_lro0.0001_lri0.001_ns63.pth', 'num_sample': 63, 'ssim': 0.9164334535598755, 'mse': array(0.00013941, dtype=float32), 'mea': array(0.00477116, dtype=float32), 'r^2': array(0.9325451, dtype=float32)}\n",
      "{'sample': 53, 'model_name': './model/normal_fineds_mse_lr0.001_ns63.pth', 'num_sample': 63, 'ssim': 0.9214386343955994, 'mse': array(0.00014531, dtype=float32), 'mea': array(0.00480734, dtype=float32), 'r^2': array(0.9073732, dtype=float32)}\n",
      "{'sample': 53, 'model_name': './model/finetune_reptilee_MSE_lro0.0001_lri0.001_ns63.pth', 'num_sample': 63, 'ssim': 0.9505395889282227, 'mse': array(0.00011372, dtype=float32), 'mea': array(0.00365251, dtype=float32), 'r^2': array(0.9275084, dtype=float32)}\n",
      "{'sample': 58, 'model_name': './model/normal_fineds_mse_lr0.001_ns63.pth', 'num_sample': 63, 'ssim': 0.8920099139213562, 'mse': array(7.8708836e-05, dtype=float32), 'mea': array(0.00489409, dtype=float32), 'r^2': array(0.95326996, dtype=float32)}\n",
      "{'sample': 58, 'model_name': './model/finetune_reptilee_MSE_lro0.0001_lri0.001_ns63.pth', 'num_sample': 63, 'ssim': 0.9280193448066711, 'mse': array(0.00015728, dtype=float32), 'mea': array(0.00450006, dtype=float32), 'r^2': array(0.9066229, dtype=float32)}\n",
      "{'sample': 59, 'model_name': './model/normal_fineds_mse_lr0.001_ns63.pth', 'num_sample': 63, 'ssim': 0.8680674433708191, 'mse': array(0.00033421, dtype=float32), 'mea': array(0.00669987, dtype=float32), 'r^2': array(0.8008548, dtype=float32)}\n",
      "{'sample': 59, 'model_name': './model/finetune_reptilee_MSE_lro0.0001_lri0.001_ns63.pth', 'num_sample': 63, 'ssim': 0.9463550448417664, 'mse': array(8.0685095e-05, dtype=float32), 'mea': array(0.00340993, dtype=float32), 'r^2': array(0.95192206, dtype=float32)}\n",
      "{'sample': 61, 'model_name': './model/normal_fineds_mse_lr0.001_ns63.pth', 'num_sample': 63, 'ssim': 0.932623565196991, 'mse': array(7.062193e-05, dtype=float32), 'mea': array(0.00377271, dtype=float32), 'r^2': array(0.90811723, dtype=float32)}\n",
      "{'sample': 61, 'model_name': './model/finetune_reptilee_MSE_lro0.0001_lri0.001_ns63.pth', 'num_sample': 63, 'ssim': 0.9538713693618774, 'mse': array(8.918001e-05, dtype=float32), 'mea': array(0.00317259, dtype=float32), 'r^2': array(0.8839722, dtype=float32)}\n",
      "{'sample': 62, 'model_name': './model/normal_fineds_mse_lr0.001_ns63.pth', 'num_sample': 63, 'ssim': 0.8584281802177429, 'mse': array(0.00028385, dtype=float32), 'mea': array(0.00723998, dtype=float32), 'r^2': array(0.83114654, dtype=float32)}\n",
      "{'sample': 62, 'model_name': './model/finetune_reptilee_MSE_lro0.0001_lri0.001_ns63.pth', 'num_sample': 63, 'ssim': 0.9374139904975891, 'mse': array(9.5002484e-05, dtype=float32), 'mea': array(0.00399559, dtype=float32), 'r^2': array(0.94348603, dtype=float32)}\n",
      "    sample  model_code                                         model_name  \\\n",
      "0       33         NaN         ./model/normal_fineds_mse_lr0.001_ns16.pth   \n",
      "1       33         NaN  ./model/finetune_reptilee_MSE_lro0.0001_lri0.0...   \n",
      "2       34         NaN         ./model/normal_fineds_mse_lr0.001_ns16.pth   \n",
      "3       34         NaN  ./model/finetune_reptilee_MSE_lro0.0001_lri0.0...   \n",
      "4       36         NaN         ./model/normal_fineds_mse_lr0.001_ns16.pth   \n",
      "..     ...         ...                                                ...   \n",
      "67      59         NaN  ./model/finetune_reptilee_MSE_lro0.0001_lri0.0...   \n",
      "68      61         NaN         ./model/normal_fineds_mse_lr0.001_ns63.pth   \n",
      "69      61         NaN  ./model/finetune_reptilee_MSE_lro0.0001_lri0.0...   \n",
      "70      62         NaN         ./model/normal_fineds_mse_lr0.001_ns63.pth   \n",
      "71      62         NaN  ./model/finetune_reptilee_MSE_lro0.0001_lri0.0...   \n",
      "\n",
      "        ssim            mse           mea         r^2  \n",
      "0   0.889549   0.0006992425   0.008096344  0.45159423  \n",
      "1   0.927987   0.0002302648   0.004752563   0.8194066  \n",
      "2   0.915366  0.00079506554    0.00642757  0.25322002  \n",
      "3   0.928630  0.00015989183  0.0042245984  0.84981865  \n",
      "4   0.890373   0.0006917946  0.0076438724   0.6376505  \n",
      "..       ...            ...           ...         ...  \n",
      "67  0.946355  8.0685095e-05  0.0034099263  0.95192206  \n",
      "68  0.932624   7.062193e-05  0.0037727111  0.90811723  \n",
      "69  0.953871   8.918001e-05  0.0031725902   0.8839722  \n",
      "70  0.858428  0.00028385027  0.0072399764  0.83114654  \n",
      "71  0.937414  9.5002484e-05  0.0039955857  0.94348603  \n",
      "\n",
      "[72 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "from loss import all_loss\n",
    "from para import*\n",
    "from normal_train import*\n",
    "time_steps=[1, 3, 6, 9]\n",
    "import pandas as pd\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)\n",
    "def plot_sample(sample, time_steps, cmap='YlOrRd', path='log',min=0, max=0.5):\n",
    "    x = np.arange(1900, 8200, 200)#32 6400\n",
    "    y = np.arange(1100, 7400, 200)#32 6400\n",
    "    z = np.arange(-2975, -2820, 10)#16 160\n",
    "    fig, ax = plt.subplots(1,len(time_steps),figsize=(5*len(time_steps), 5),subplot_kw={'projection': '3d'})\n",
    "    X,Y,Z = np.meshgrid(x, y, z)\n",
    "    # min=0\n",
    "    # max=np.max(sample)\n",
    "    for i, time_step in enumerate(time_steps):\n",
    "        grid_t=sample[0,time_step]\n",
    "        ax[i].set_box_aspect([1, 1, 0.2])\n",
    "        cur_ax=ax[i].scatter(X[:], Y[:], Z[:],s=100,c=grid_t[:], marker='.', cmap=cmap,vmin=min, vmax=max)\n",
    "        ax[i].set_xticks([])\n",
    "        ax[i].set_yticks([])\n",
    "        ax[i].set_zticks([])\n",
    "    fig.colorbar(cur_ax,ax=ax,shrink=0.6)\n",
    "    if path is not None:\n",
    "        fig.savefig(f\"{path}.png\",dpi=500)\n",
    "    fig.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "ns_ls=[16,32,63]\n",
    "model_list=[]\n",
    "para_log=[]\n",
    "for ns in ns_ls:\n",
    "    model_list.append([f\"./saved_model/normal_fineds_mse_lr{LR}_ns{ns}.pth\",f\"./saved_model/finetune_reptilee_MSE_lro0.0001_lri0.001_ns{ns}.pth\"])\n",
    "for i,model_path in enumerate(model_list):\n",
    "        model = build_resunetplusplus()\n",
    "        for target_sample in [33,34,36,37,38,51,52,53,58,59,61,62]:\n",
    "            x=np.load(\"./target_task/data_normal/all_x.npy\")[target_sample]\n",
    "            y=np.load(\"./target_task/data_normal/all_y.npy\")[target_sample]\n",
    "            if(i==0):\n",
    "                plot_sample(y[0:1,:], time_steps, path=f\"sample_target_{target_sample}\")\n",
    "            x=torch.tensor(x[0:1,:], dtype=torch.float32).to(DEVICE)\n",
    "            y=torch.tensor(y[0:1,:], dtype=torch.float32).to(DEVICE)\n",
    "            y_pred_ls=[]\n",
    "            y_error_ls=[]\n",
    "            y_error_max=0\n",
    "            y_pred_max=0\n",
    "            for j in range(2):\n",
    "                checkpoint = torch.load(model_path[j])\n",
    "                model.load_state_dict(checkpoint)\n",
    "                model = model.to(DEVICE)\n",
    "                y_pred = model(x)\n",
    "                y_error = torch.abs(y_pred - y)\n",
    "                loss_ms, loss_me, loss_r, loss_s = all_loss(y_pred, y)\n",
    "                para_log_i={\n",
    "                        'sample': target_sample,\n",
    "                        'model_name': model_path[j],\n",
    "                        'num_sample': ns_ls[i],\n",
    "                        'ssim': 1-loss_s.data.cpu().numpy(),\n",
    "                        'mse': loss_ms.data.cpu().numpy(),\n",
    "                        'mea': loss_me.data.cpu().numpy(),\n",
    "                        'r^2': loss_r.data.cpu().numpy(),\n",
    "                    }\n",
    "                para_log.append(para_log_i)\n",
    "                print(para_log_i)\n",
    "                y_error = y_error.cpu().detach().numpy()\n",
    "                y_pred = y_pred.cpu().detach().numpy()\n",
    "                y_error_ls.append(y_error)\n",
    "                y_pred_ls.append(y_pred)\n",
    "                if np.max(y_error)>y_error_max:\n",
    "                    y_error_max = np.max(y_error)\n",
    "                if np.max(y_pred)>y_pred_max:\n",
    "                    y_pred_max = np.max(y_pred)\n",
    "            plot_sample(y_pred_ls[0], time_steps, path=f\"normal_model_ns{ns_ls[i]}_sample{target_sample}\",max=y_pred_max,min=0)\n",
    "            plot_sample(y_error_ls[0], time_steps, cmap='Reds', path=f\"normal_error_ns{ns_ls[i]}_sample{target_sample}\",max=y_error_max,min=0)\n",
    "            plot_sample(y_pred_ls[1], time_steps, path=f\"reptile_model_ns{ns_ls[i]}_sample{target_sample}\",max=y_pred_max,min=0)\n",
    "            plot_sample(y_error_ls[1], time_steps, cmap='Reds', path=f\"reptile_error_ns{ns_ls[i]}_sample{target_sample}\",max=y_error_max,min=0)\n",
    "           \n",
    "name=['sample','model_code', 'model_name','ssim','mse','mea','r^2']\n",
    "test=pd.DataFrame(columns=name,data=para_log)\n",
    "print(test)\n",
    "test.to_csv(f\"./modellogcsv_{target_sample}.csv\",encoding='gbk')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
